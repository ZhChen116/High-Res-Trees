{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN group size: 229\n",
      "AD group size: 187\n",
      "LMCI group size: 401\n",
      "CN 4D tensor shape: (229, 48, 48, 48)\n",
      "CN y shape: (229,)\n",
      "AD 4D tensor shape: (187, 48, 48, 48)\n",
      "AD y shape: (187,)\n",
      "LMCI 4D tensor shape: (401, 48, 48, 48)\n",
      "LMCI y shape: (401,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from skimage.measure import block_reduce\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorly as tl\n",
    "\n",
    "#Debugging import\n",
    "import importlib\n",
    "var = 'TensorDecisionTreeRegressorP' #the published version of code\n",
    "package = importlib.import_module(var)\n",
    "for name, value in package.__dict__.items():\n",
    "    if not name.startswith(\"__\"):\n",
    "        globals()[name] = value\n",
    "\n",
    "from TensorDecisionTreeRegressorP import *\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# File path to the CSV file\n",
    "csv_file = '/Users/zhihaochen/Documents/CommenDesktop/RICE/MyProject/Bayes_Tensor_Tree/3D-images/ADNIData.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "# Remove rows where ADAS11_bl is missing (NaN)\n",
    "df_cleaned = df.dropna(subset=['ADAS11_bl'])\n",
    "\n",
    "# Extract the 'ADAS11_bl' column as the y variable\n",
    "y_variable = df_cleaned['ADAS11_bl'].values\n",
    "\n",
    "# Split the dataframe based on the DX_bl column values\n",
    "cn_group = df_cleaned[df_cleaned['DX_bl'] == 'CN']\n",
    "ad_group = df_cleaned[df_cleaned['DX_bl'] == 'AD']\n",
    "lmci_group = df_cleaned[df_cleaned['DX_bl'] == 'LMCI']\n",
    "\n",
    "# Display the counts for each group after removing NA\n",
    "print(f\"CN group size: {cn_group.shape[0]}\")\n",
    "print(f\"AD group size: {ad_group.shape[0]}\")\n",
    "print(f\"LMCI group size: {lmci_group.shape[0]}\")\n",
    "\n",
    "# Directory containing the 3D images\n",
    "directory = '/Users/zhihaochen/Documents/CommenDesktop/RICE/MyProject/Bayes_Tensor_Tree/3D-images/3D-Images/bl'\n",
    "\n",
    "# Initialize dictionaries to hold the images and y values for each group\n",
    "cn_images, ad_images, lmci_images = [], [], []\n",
    "cn_y, ad_y, lmci_y = [], [], []\n",
    "\n",
    "# Function to load the images based on PTID matching and append y values\n",
    "def load_images_and_y(group, image_list, y_list):\n",
    "    for _, row in group.iterrows():\n",
    "        ptid = row['PTID']\n",
    "        # Find the corresponding file based on PTID\n",
    "        filename = f'{ptid}.nii.gz'\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Load the NIfTI file\n",
    "            img = nib.load(file_path)\n",
    "            data = img.get_fdata()\n",
    "            \n",
    "            # Append the 3D image data and y value to the respective lists\n",
    "            image_list.append(data)\n",
    "            y_list.append(row['ADAS11_bl'])\n",
    "        else:\n",
    "            print(f\"File {filename} not found.\")\n",
    "\n",
    "# Load images and y values for each group\n",
    "load_images_and_y(cn_group, cn_images, cn_y)\n",
    "load_images_and_y(ad_group, ad_images, ad_y)\n",
    "load_images_and_y(lmci_group, lmci_images, lmci_y)\n",
    "\n",
    "# Convert lists of 3D images and y values to NumPy arrays\n",
    "if cn_images:\n",
    "    cn_tensor = np.stack(cn_images, axis=0)\n",
    "    cn_y = np.array(cn_y)\n",
    "    print(f\"CN 4D tensor shape: {cn_tensor.shape}\")\n",
    "    print(f\"CN y shape: {cn_y.shape}\")\n",
    "else:\n",
    "    print(\"No CN images loaded.\")\n",
    "\n",
    "if ad_images:\n",
    "    ad_tensor = np.stack(ad_images, axis=0)\n",
    "    ad_y = np.array(ad_y)\n",
    "    print(f\"AD 4D tensor shape: {ad_tensor.shape}\")\n",
    "    print(f\"AD y shape: {ad_y.shape}\")\n",
    "else:\n",
    "    print(\"No AD images loaded.\")\n",
    "\n",
    "if lmci_images:\n",
    "    lmci_tensor = np.stack(lmci_images, axis=0)\n",
    "    lmci_y = np.array(lmci_y)\n",
    "    print(f\"LMCI 4D tensor shape: {lmci_tensor.shape}\")\n",
    "    print(f\"LMCI y shape: {lmci_y.shape}\")\n",
    "else:\n",
    "    print(\"No LMCI images loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.linalg import cholesky, inv\n",
    "import math\n",
    "import time\n",
    "from functools import reduce\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.1)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "from scipy.special import gammaln, logsumexp\n",
    "from sklearn.linear_model import LassoCV\n",
    "import itertools\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "from scipy.stats import geninvgauss\n",
    "\n",
    "def getouter_list(bet):\n",
    "    d = len(bet)\n",
    "    if d == 1:\n",
    "        return bet[0]\n",
    "    elif d == 2:\n",
    "        return np.outer(bet[0], bet[1]).reshape(bet[0].shape + bet[1].shape)\n",
    "    else:\n",
    "        return np.outer(getouter_list(bet[:-1]), bet[-1]).reshape(getouter_list(bet[:-1]).shape + bet[-1].shape)\n",
    "\n",
    "def getmean(X, beta, rank, rank_exclude=None):\n",
    "    if rank_exclude is None:\n",
    "        rank_exclude = []\n",
    "\n",
    "    idx = [i for i in range(rank) if i not in rank_exclude]\n",
    "    B_list = [getouter_list([beta_elem[r, :] for beta_elem in beta]) for r in idx]\n",
    "    B = reduce(lambda x, y: x + y, B_list)\n",
    "    def compute_sum(xx, bb):\n",
    "        return np.sum(xx * bb)\n",
    "    mu_B = np.array([compute_sum(xx, B) for xx in X])\n",
    "    return mu_B\n",
    "\n",
    "def logsum(lx):\n",
    "    max_lx = np.max(lx)\n",
    "    return max_lx + np.log(np.sum(np.exp(lx - max_lx)))\n",
    "\n",
    "def TP_rankR(X_allr):\n",
    "    R = X_allr[0].shape[1] if len(X_allr[0].shape) > 1 else None\n",
    "    if R is None:\n",
    "        return getouter_list(X_allr)\n",
    "    else:\n",
    "        dims = [x.shape[0] for x in X_allr]\n",
    "        Y = np.zeros(dims)\n",
    "        for r in range(R):\n",
    "            outer_results = [x[:, r] for x in X_allr]\n",
    "            Y += getouter_list(outer_results)\n",
    "        return Y\n",
    "\n",
    "def getBeta_mcmc(beta_store):\n",
    "    nsweep = len(beta_store)\n",
    "    d = len(beta_store[0])\n",
    "    rank = beta_store[0][0].shape[0]\n",
    "    p = [beta_store[0][x].shape[1] for x in range(d)]\n",
    "    Beta_mcmc = np.zeros((nsweep, np.prod(p)))\n",
    "    \n",
    "    for i in range(nsweep):\n",
    "        coef = np.zeros(np.prod(p))\n",
    "        for r in range(rank):\n",
    "            outer_list = [beta_store[i][x][r, :] for x in range(d)]\n",
    "            coef += getouter_list(outer_list).flatten()\n",
    "        Beta_mcmc[i, :] = coef    \n",
    "    return Beta_mcmc\n",
    "\n",
    "####main function####\n",
    "def tensor_reg(z_train, x_train, y_train, a_lam, b_lam, phi_alpha, nsweep=1e3, rank=5, burn=0.30,\n",
    "               nskip=3, scale=True, plot=False):\n",
    "    \n",
    "    \n",
    "    n = len(y_train)\n",
    "    p = x_train.shape[1:]\n",
    "    d = len(x_train.shape)-1\n",
    "    pgamma = z_train.shape[1]\n",
    "    \n",
    "\n",
    "    #### standarize ####\n",
    "    my = np.mean(y_train)\n",
    "    sy = np.std(y_train, ddof=1) if scale else 1\n",
    "    if scale:\n",
    "        obs = (y_train - my) / sy\n",
    "    else:\n",
    "        obs = y_train\n",
    "    if scale:\n",
    "        mz = np.mean(z_train, axis=0)\n",
    "        sz = np.array([np.max(z_train[:, i]) - np.min(z_train[:, i]) for i in range(pgamma)])\n",
    "        sz[sz==0] = 1\n",
    "        Zt = np.zeros_like(z_train, dtype=float)\n",
    "        for jj in range(pgamma):\n",
    "            Zt[:,jj] = (z_train[:,jj] - mz[jj]) / sz[jj] \n",
    "    \n",
    "        Xt = np.zeros_like(x_train, dtype=float)\n",
    "        mx = np.mean(x_train, axis=0)\n",
    "        def range_diff(z):\n",
    "            return np.nanmax(z) - np.nanmin(z)\n",
    "        sx = np.apply_along_axis(range_diff, axis=0, arr=x_train)\n",
    "        sx[sx == 0] <- 1\n",
    "   \n",
    "        if d == 2:\n",
    "            for jj in range(n):\n",
    "                Xt[jj,:,:] = (x_train[jj,:,:] - mx) / sx\n",
    "        elif d == 3:\n",
    "            for jj in range(n):\n",
    "                Xt[jj,:,:,:] = (x_train[jj,:,:,:] - mx) / sx\n",
    " \n",
    "    else:\n",
    "        Zt = z_train\n",
    "        Xt = x_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    x_train_nona = Xt\n",
    "    #### MCMC setup ####\n",
    "    ZZ = np.dot(Zt.T, Zt)\n",
    "    vecXt = Xt.reshape(n, np.prod(p))\n",
    "    vecXt = np.hstack((z_train, vecXt))\n",
    "\n",
    "\n",
    "    las = LassoCV(cv=5).fit(vecXt, y_train)\n",
    "    beta_init = las.coef_\n",
    "    gam = beta_init[0:pgamma]\n",
    "\n",
    "    ##hyper-par initialize\n",
    "    a_lam = None; b_lam = None; phi_alpha = None\n",
    "    if a_lam is None:\n",
    "        a_lam = [3.0] * rank\n",
    "        a_lam = np.array(a_lam)\n",
    "    if b_lam is None:\n",
    "        b_lam = a_lam**(1/(2*d))\n",
    "    if phi_alpha is None:\n",
    "        phi_alpha = np.array([1/rank]*rank)\n",
    "    phi_a0 = np.sum(phi_alpha)\n",
    "    a_vphi = phi_a0\n",
    "    b_vphi = phi_alpha[1] * rank**(1/d)\n",
    "    c0 = 0\n",
    "    s0 = 1; a_t = 2_5/2; b_t = 2.5/2 * s0**2\n",
    "\n",
    "    ##fix randomness for now\n",
    "    tau2  = 1 / np.random.gamma(size = 1, shape = a_t, scale=1/b_t)\n",
    "    #tau2 = 2\n",
    "    phi = np.random.dirichlet(phi_alpha, size = 1)\n",
    "    varphi = np.random.gamma(size = 1, shape = a_vphi, scale=1/b_vphi)\n",
    "    #varphi = 0.5\n",
    "    tau_r = phi * varphi\n",
    "    # Define the flatten function\n",
    "    def flatten(nested_list):\n",
    "        return [item for sublist in nested_list for item in sublist]\n",
    "    tau_r = flatten(tau_r)\n",
    "    \n",
    "    lambda_ = np.array([1.5]*rank*d).reshape((rank, d))\n",
    "    omega = [None]*d\n",
    "    for x in range(d):\n",
    "        omega[x] = np.random.exponential(scale=.5*(a_lam[1]/b_lam[1]), size=(rank,p[x]))\n",
    "\n",
    "    beta = [None]*d\n",
    "    for x in range(d):\n",
    "        beta[x] = np.random.normal(size = (rank,p[x]))\n",
    "\n",
    "    ##initialize tensor margins\n",
    "    alpha_store = [None]*nsweep\n",
    "    c0_store = [None]*nsweep\n",
    "    gam_store = np.array([None]*nsweep*pgamma).reshape(nsweep,pgamma)\n",
    "    tau2_store = [None]*nsweep\n",
    "    phi_store = np.array([None]*nsweep*rank).reshape(nsweep,rank)\n",
    "    phi_store\n",
    "    varphi_store = np.array([None]*nsweep*rank).reshape(-1,1)\n",
    "    varphi_store\n",
    "    beta_store = [[None]*d]*nsweep\n",
    "    for x in range(nsweep):\n",
    "        for y in range(d):\n",
    "            beta_store[x][y] = np.array([None]*rank*p[y]).reshape(rank,p[y])\n",
    "    beta_store\n",
    "    omega_store = [[None]*d]*nsweep\n",
    "    for x in range(nsweep):\n",
    "        for y in range(d):\n",
    "            omega_store[x][y] = np.array([None]*rank*p[y]).reshape(rank,p[y])\n",
    "    lambda_store = np.array([None]*nsweep*rank*d).reshape(nsweep,rank, d)\n",
    "    #hyppar_store = np.array([None]*nsweep*rank*d).reshape(nsweep,rank, 2)\n",
    "    hyppar_store = np.zeros((nsweep, rank, 2))\n",
    "\n",
    "    alam_seq = np.linspace(2.1, d + 1, num=5)\n",
    "    zeta_max = np.ceil(10 * rank**(1 / (2 * d)) / 2) / 10\n",
    "    zeta_seq = np.linspace(0.5, zeta_max, num=5)\n",
    "    param_grid = list(itertools.product(alam_seq, zeta_seq))\n",
    "    par_grid = pd.DataFrame(param_grid, columns=['alam', 'zeta'])\n",
    "    alam_seq = np.linspace(2.1, d + 1, num=5)\n",
    "    zeta_max = np.ceil(10 * rank**(1 / (2 * d)) / 2) / 10\n",
    "    zeta_seq = np.linspace(0.5, zeta_max, num=5)\n",
    "    alam_grid, zeta_grid = np.meshgrid(alam_seq, zeta_seq)\n",
    "    par_grid = pd.DataFrame({\n",
    "        'alam': alam_grid.flatten(),\n",
    "        'zeta': zeta_grid.flatten()\n",
    "    })\n",
    "    par_grid = par_grid.values\n",
    "    alpha_grid = np.linspace(rank**(-d), rank**(-0.1), num=10)\n",
    "    M=20\n",
    "    score_store = np.array([None]*nsweep*len(alpha_grid)).reshape(nsweep,len(alpha_grid))\n",
    "\n",
    "    #### MCMC run ####\n",
    "    start_time = time.time()\n",
    "    for sweep in range(nsweep):\n",
    "        tens_mean = getmean(x_train_nona, beta, rank)\n",
    "        Cjr = np.zeros((d, rank))\n",
    "        for rr in range(rank):\n",
    "            for jj in range(d):\n",
    "                bb = np.sum(np.abs(beta[jj][rr, :]))\n",
    "                Cjr[jj, rr] = bb / np.sqrt(tau_r[rr])\n",
    "                #print(\"Cjr[jj, rr]: \", Cjr[jj, rr])\n",
    "        def mfun(z, rank, p, Cjr):\n",
    "            o = [gammaln(z[0] + p[x]) - gammaln(z[0]) + z[0] * math.log(z[1] * z[0]) - (z[0] + p[x]) * math.log(z[1] * z[0] + Cjr[x][rank]) for x in range(d)]\n",
    "            return sum(o)\n",
    "        \n",
    "        ll = np.zeros((par_grid.shape[0], rank))\n",
    "        for rr in range(rank):\n",
    "            for z in range(par_grid.shape[0]):\n",
    "                result = mfun(par_grid[z], rr, p, Cjr)\n",
    "                ll[z, rr] = result\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        par_wt = np.apply_along_axis(lambda z: np.exp(z - logsum(z)), axis=0, arr=ll)\n",
    "        #par_wt = np.apply_along_axis(lambda z: np.exp(z - np.log(np.sum(z))), axis=0, arr=ll)\n",
    "        par_wt = np.nan_to_num(par_wt, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        for i in range(par_wt.shape[1]):\n",
    "            par_wt[:,i] = par_wt[:,i]/np.sum(par_wt[:,i])\n",
    "        par_wt = np.nan_to_num(par_wt, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        # Convert the cleaned NumPy array back to a list\n",
    "        #cleaned_list = cleaned_array.tolist()\n",
    "        #print(\"par_wt:\", sum(par_wt)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        indices = np.arange(par_grid.shape[0])\n",
    "        ixx = np.zeros(par_wt.shape[1], dtype=int)\n",
    "        for i in range(par_wt.shape[1]):\n",
    "            ixx[i] = np.random.choice(indices, size=1, p=par_wt[:, i])[0]\n",
    "        \n",
    "        for rr in range(rank):\n",
    "            a_lam[rr] = par_grid[ixx[rr], 0]\n",
    "            b_lam[rr] = par_grid[ixx[rr], 1] * a_lam[rr]\n",
    "        np.set_printoptions(precision=10, suppress=False)\n",
    "\n",
    "        ##update gamma\n",
    "        diag_pgamma = np.diag(np.ones(pgamma))\n",
    "        cho_factor_matrix = cho_factor(diag_pgamma + ZZ / tau2)\n",
    "        Sig_g = cho_solve(cho_factor_matrix, np.eye(pgamma))\n",
    "        mu_g = np.dot(Sig_g, np.dot(Zt.T, (obs - c0 - tens_mean)) / tau2)\n",
    "        rnorm_pgamma = np.random.normal(size=pgamma)\n",
    "        gam = mu_g + np.dot(np.linalg.cholesky(Sig_g), rnorm_pgamma)\n",
    "\n",
    "        ## update alpha (intercept)\n",
    "        pred_mean = np.dot(Zt, gam)\n",
    "        mu_c0 = np.mean(obs - pred_mean - tens_mean)\n",
    "        c0 = np.random.normal(loc=mu_c0, scale=np.sqrt(tau2 / n))\n",
    "        \n",
    "        ## update tau2\n",
    "        a_tau = a_t + n / 2\n",
    "        b_tau = b_t + 0.5 * np.sum((obs - c0 - pred_mean - tens_mean)**2)\n",
    "        tau2 = 1 / stats.gamma.rvs(a=a_tau, scale=1/b_tau)\n",
    "\n",
    "        ## update (alpha, phi, varphi)\n",
    "        def draw_phi_tau(alpha_grid):\n",
    "            length = len(alpha_grid)\n",
    "\n",
    "            # Precompute Cr matrix\n",
    "            Cr = np.array([\n",
    "                [\n",
    "                    np.dot(beta[jj][rr, :], np.dot(np.diag(1 / omega[jj][rr, :]), beta[jj][rr, :]))\n",
    "                    for rr in range(rank)\n",
    "                ]\n",
    "                for jj in range(d)\n",
    "            ])\n",
    "\n",
    "            def score_fn(phi_alpha, phi_s, varphi_s, Cstat):\n",
    "                def ldirdens(v, a):\n",
    "                    c1 = gammaln(np.sum(a))\n",
    "                    c2 = np.sum(gammaln(a))\n",
    "                    return (c1 - c2) + np.sum((a - 1) * np.log(np.maximum(v, 1e-10)))  \n",
    "\n",
    "                ldir = np.apply_along_axis(ldirdens, 1, phi_s, a=phi_alpha)\n",
    "\n",
    "                lvarphi = stats.gamma.logpdf(varphi_s, a=np.sum(phi_alpha), scale=1/b_vphi)\n",
    "                \n",
    "                dnorm_log = -np.sum(Cstat, axis=1) / (2 * np.maximum(varphi_s, 1e-10)) \n",
    "                dnorm_log -= (np.sum(p) / 2) * np.array([np.sum(np.log(np.maximum(varphi_s[ii] * phi_s[ii, :], 1e-10))) for ii in range(len(varphi_s))])  # Avoid log(0)\n",
    "                \n",
    "                return dnorm_log + ldir + lvarphi\n",
    "\n",
    "            if length > 1:\n",
    "                phi = np.zeros((M * length, rank))\n",
    "                varphi = np.zeros((M * length, 1))\n",
    "                Cstat = np.zeros((M * length, rank))\n",
    "                \n",
    "                for jj in range(length):\n",
    "                    m_phialpha = np.full(rank, alpha_grid[jj])\n",
    "                    m_phia0 = np.sum(m_phialpha)\n",
    "                    m_avphi = m_phia0\n",
    "\n",
    "                    # Draw phi\n",
    "                    Cr1 = np.sum(Cr, axis=0)\n",
    "                    phi_a = np.array([geninvgauss.rvs(m_phialpha[rr] - np.sum(p)/2, Cr1[rr], scale=2 * b_vphi, size=M) for rr in range(rank)]).T\n",
    "                    phi_a = np.apply_along_axis(lambda z: z / np.sum(z), 1, phi_a)\n",
    "\n",
    "                    # Draw varphi\n",
    "                    Cr2 = np.apply_along_axis(lambda z: Cr1 / np.maximum(z, 1e-10), 1, phi_a)  # Avoid division by zero\n",
    "                    varphi_a = np.array([geninvgauss.rvs(m_avphi - rank * np.sum(p)/2, 2 * b_vphi, scale=np.sum(z)) for z in Cr2]).flatten()\n",
    "\n",
    "                    phi[jj * M:(jj + 1) * M, :] = phi_a\n",
    "                    varphi[jj * M:(jj + 1) * M, 0] = varphi_a\n",
    "                    Cstat[jj * M:(jj + 1) * M, :] = Cr2\n",
    "\n",
    "                scores = [score_fn(np.full(rank, z), phi, varphi, Cstat) for z in alpha_grid]\n",
    "                scores = np.array(scores)\n",
    "                lmax = np.max(scores)\n",
    "                normalized_scores = np.array([np.mean(np.exp(score - lmax)) for score in scores])\n",
    "                normalized_scores /= np.sum(normalized_scores)  # Ensure scores sum to 1\n",
    "            else:\n",
    "                m_phialpha = np.full(rank, alpha_grid[0])\n",
    "                m_phia0 = np.sum(m_phialpha)\n",
    "                m_avphi = m_phia0\n",
    "\n",
    "                Cr1 = np.sum(Cr, axis=0)\n",
    "\n",
    "                # Draw phi\n",
    "                phi = np.array([geninvgauss.rvs(m_phialpha[rr] - np.sum(p) / 2, 2 * b_vphi, scale=Cr1[rr], size=1) for rr in range(rank)]).flatten()\n",
    "                phi = phi / np.sum(phi)\n",
    "\n",
    "                # Draw varphi\n",
    "                Cr2 = Cr1 / np.maximum(phi, 1e-10)  # Avoid division by zero\n",
    "                varphi = geninvgauss.rvs(m_avphi - rank * np.sum(p) / 2, 2 * b_vphi, scale=np.sum(Cr2), size=1)\n",
    "\n",
    "                scores = score_fn(m_phialpha, np.array([phi]), np.array([varphi]), np.array([Cr2]))\n",
    "                scores = np.array([scores])\n",
    "                lmax = np.max(scores)\n",
    "                normalized_scores = np.array([np.mean(np.exp(scores - lmax))])\n",
    "                normalized_scores /= np.sum(normalized_scores)  # Ensure scores sum to 1\n",
    "\n",
    "            return {'phi': phi, 'varphi': varphi, 'scores': normalized_scores}\n",
    "        ## sample astar\n",
    "        o = draw_phi_tau(alpha_grid)\n",
    "        scores = o['scores']\n",
    "        normalized_scores = scores / np.sum(scores)\n",
    "        astar = np.random.choice(alpha_grid, size=1, p=normalized_scores)\n",
    "        score_store[sweep, :] = normalized_scores\n",
    "\n",
    "        # Sample (phi, varphi) based on astar\n",
    "        o = draw_phi_tau(astar)\n",
    "        phi = o['phi']\n",
    "        varphi = o['varphi']\n",
    "\n",
    "        # Calculate tau.r\n",
    "        tau_r = varphi * phi\n",
    "        #print(\"tau_r: \", tau_r)\n",
    "        # Define phi.alpha, phi.a0, and a.vphi\n",
    "        phi_alpha = np.full(rank, astar)\n",
    "        phi_a0 = np.sum(phi_alpha)\n",
    "        a_vphi = phi_a0\n",
    "\n",
    "        ## update rank specific params\n",
    "        lambda_ = np.zeros((rank, len(beta)))\n",
    "        for r in range(rank):\n",
    "            for j in range(d):\n",
    "                tens_mu_r = getmean(x_train_nona, beta, rank, [r])\n",
    "                    \n",
    "                betj = getouter_list([beta_elem[r, :] for k, beta_elem in enumerate(beta) if k != j])\n",
    "                    \n",
    "                H = np.full((n, p[j]), np.nan)\n",
    "                for i in range(n):\n",
    "                    if d == 2:\n",
    "                        if j == 0:\n",
    "                            H[i, :] = [np.sum(x_train_nona[i, k, :] * betj) for k in range(p[j])]\n",
    "                        elif j == 1:\n",
    "                                H[i, :] = [np.sum(x_train_nona[i, :, k] * betj) for k in range(p[j])]\n",
    "                    elif d == 3:\n",
    "                        if j == 0:\n",
    "                            H[i, :] = [np.sum(x_train_nona[i, k, :, :] * betj) for k in range(p[j])]\n",
    "                        elif j == 1:\n",
    "                            H[i, :] = [np.sum(x_train_nona[i, :, k, :] * betj) for k in range(p[j])]\n",
    "                        elif j == 2:\n",
    "                            H[i, :] = [np.sum(x_train_nona[i, :, :, k] * betj) for k in range(p[j])]\n",
    "                #print(\"H: \", H)\n",
    "                HH = np.dot(H.T, H)\n",
    "                #print(\"HH: \", HH)\n",
    "                diag_elements = 1 / omega[j][r, :] / tau_r[r]\n",
    "                diag_matrix = np.diag(diag_elements)\n",
    "                #print(\"HH / tau2 + diag_matrix: \", HH / tau2 + diag_matrix)\n",
    "                chol_matrix = cholesky(HH / tau2 + diag_matrix)\n",
    "                K = inv(chol_matrix.T @ chol_matrix)\n",
    "                #K = inv(chol_matrix)\n",
    "                #print(\"K:\", K)\n",
    "                \n",
    "                ##update betas\n",
    "                mm = obs - c0 - pred_mean - tens_mu_r\n",
    "                bet_mu_jr = K @ ((H.T/tau2)@ mm)\n",
    "                chol_K = cholesky(K, lower=True)\n",
    "                beta[j][r, :] = bet_mu_jr + chol_K @ np.random.randn(p[j])\n",
    "\n",
    "                ## update lambda.jr\n",
    "                shape = a_lam[r] + p[j]\n",
    "                rate = b_lam[r] + np.sum(np.abs(beta[j][r, :])) / np.sqrt(tau_r[r]) \n",
    "                lambda_[r, j] = np.random.gamma(shape, 1.0 / rate)\n",
    "                ## update omega.jr\n",
    "                omega[j][r, :] = [geninvgauss.rvs(0.5, beta[j][r, kk]**2 / tau_r[r], scale=lambda_[r, j]**2) for kk in range(p[j])]\n",
    "        \n",
    "        ## store params\n",
    "        tau2_store[sweep] = tau2\n",
    "        c0_store[sweep] = c0\n",
    "        if z_train is not None:\n",
    "            gam_store[sweep, :] = gam\n",
    "        else:\n",
    "            gam_store[sweep] = gam\n",
    "        alpha_store[sweep] = astar\n",
    "        phi_store[sweep, :] = phi\n",
    "        varphi_store[sweep, :] = varphi\n",
    "        beta_store[sweep] = beta\n",
    "        omega_store[sweep] = omega\n",
    "        lambda_store[sweep, :, :] = lambda_\n",
    "        for rr in range(rank):\n",
    "            hyppar_store[sweep, rr, :] = [a_lam[rr], b_lam[rr]]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        #if sweep % 5 == 0:\n",
    "            #print(f\"{sweep}, tau2: {tau2 * sy**2:.3f}, (alpha, a.lam, b.lam): {astar:.3f}, {a_lam[r]:.3f}, {b_lam[r]:.3f}\")\n",
    "    \n",
    "    # Example time-consuming operation\n",
    "    time.sleep(0.01)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = abs(end_time - start_time)\n",
    "    print('Time out:', elapsed_time)\n",
    "\n",
    "    out = {\n",
    "    \"nsweep\": nsweep,\n",
    "    \"rank\": rank,\n",
    "    \"p\": p,\n",
    "    \"d\": d,\n",
    "    \"par_grid\": par_grid,\n",
    "    \"alpha_grid\": alpha_grid,\n",
    "    \"my\": my,\n",
    "    \"sy\": sy,\n",
    "    \"mz\": mz,\n",
    "    \"sz\": sz,\n",
    "    \"mx\": mx,\n",
    "    \"sx\": sx,\n",
    "    \"Zt\": Zt,\n",
    "    \"Xt\": Xt,\n",
    "    \"obs\": obs,\n",
    "    \"a_t\": a_t,\n",
    "    \"b_t\": b_t,\n",
    "    \"tau2_store\": tau2_store,\n",
    "    \"c0_store\": c0_store,\n",
    "    \"gam_store\": gam_store,\n",
    "    \"alpha_store\": alpha_store,\n",
    "    \"beta_store\": beta_store,\n",
    "    \"phi_store\": phi_store,\n",
    "    \"varphi_store\": varphi_store,\n",
    "    \"omega_store\": omega_store,\n",
    "    \"lambda_store\": lambda_store,\n",
    "    \"hyppar_store\": hyppar_store,\n",
    "    \"score_store\": score_store,\n",
    "    \"time\": elapsed_time\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))  # 3 rows, 1 column, big figure size\n",
    "\n",
    "# Plotting data1 in the first subplot\n",
    "axes[0].hist(lmci_y)\n",
    "axes[0].set_title('lmci_y Distribution')\n",
    "\n",
    "# Plotting data2 in the second subplot\n",
    "axes[1].hist(ad_y)\n",
    "axes[1].set_title('ad_y Distribution')\n",
    "\n",
    "# Plotting data3 in the third subplot\n",
    "axes[2].hist(cn_y)\n",
    "axes[2].set_title('cn_y Distribution')\n",
    "\n",
    "# Adjusting layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 48, 48, 48) (320,)\n",
      "(320, 12, 12, 12) (320,) (81, 12, 12, 12)\n",
      "mean train RSE:  0.6661496723911483\n",
      "CP train RSE:  0.0003328366478028351\n",
      "Tucker train RSE:  0.0001434490040138438\n",
      "mean test RSE:  1.1447560359477025\n",
      "CP test RSE:  2.2759120638649\n",
      "Tucker test RSE:  2.1283791440847315\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lmci_tensor, lmci_y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "model  =  TensorDecisionTreeRegressor(max_depth=3, min_samples_split=12,split_method='variance_LS', split_rank=4, CP_reg_rank=12, Tucker_reg_rank=12, n_mode=3)\n",
    "model.use_mean_as_threshold  =  False\n",
    "model.sample_rate  =  .5\n",
    "X_coarsen_shape = (1,4,4,4)\n",
    "X_coarsen_func = np.mean\n",
    "X_train_c = block_reduce(X_train,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_test_c = block_reduce(X_test,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "#middle_z = X_train_c.shape[2] // 2\n",
    "#X_train_c = X_train_c[:,:,:,middle_z:middle_z+2]\n",
    "#X_test_c = X_test_c[:,:,:,middle_z:middle_z+2]\n",
    "X_train_c = X_train_c+np.ones_like(X_train_c)*1e-3\n",
    "print(X_train_c.shape,y_train.shape,X_test_c.shape)\n",
    "model.fit(X_train_c,y_train)\n",
    "\n",
    "predictions = model.predict(X_train_c,regression_method='mean')\n",
    "print(f\"mean train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_train_c,regression_method='cp')\n",
    "print(f\"CP train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_train_c,regression_method='tucker')\n",
    "print(f\"Tucker train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train)) \n",
    "\n",
    "predictions = model.predict(X_test_c,regression_method='mean')\n",
    "print(f\"mean test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_test_c,regression_method='cp')\n",
    "print(f\"CP test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_test_c,regression_method='tucker')\n",
    "print(f\"Tucker test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  if X[:, 7 , 5 , 3 ] <=  1.7269168438613414\n",
      "   if X[:, 4 , 7 , 8 ] <=  0.0698931760378182\n",
      "     if X[:, 4 , 8 , 9 ] <=  0.03768671287596226\n",
      "         has  0  child nodes, and  2  samples.\n",
      "     else: # if X[:, 4 , 8 , 9 ] >  0.03768671287596226\n",
      "         has  0  child nodes, and  87  samples.\n",
      "   else: # if X[:, 4 , 7 , 8 ] >  0.0698931760378182\n",
      "     if X[:, 10 , 7 , 3 ] <=  0.8018943796157837\n",
      "         has  0  child nodes, and  8  samples.\n",
      "     else: # if X[:, 10 , 7 , 3 ] >  0.8018943796157837\n",
      "         has  0  child nodes, and  68  samples.\n",
      "  else: # if X[:, 7 , 5 , 3 ] >  1.7269168438613414\n",
      "   if X[:, 8 , 7 , 1 ] <=  3.0189043784737586\n",
      "     if X[:, 5 , 6 , 8 ] <=  0.35621589033305645\n",
      "         has  0  child nodes, and  106  samples.\n",
      "     else: # if X[:, 5 , 6 , 8 ] >  0.35621589033305645\n",
      "         has  0  child nodes, and  37  samples.\n",
      "   else: # if X[:, 8 , 7 , 1 ] >  3.0189043784737586\n",
      "     if X[:, 7 , 5 , 8 ] <=  3.9584479460716246\n",
      "         has  0  child nodes, and  7  samples.\n",
      "     else: # if X[:, 7 , 5 , 8 ] >  3.9584479460716246\n",
      "         has  0  child nodes, and  5  samples.\n"
     ]
    }
   ],
   "source": [
    "model.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf Node 1: Leaf node 1.1.1 (2 samples), Samples Shape: (2, 12, 12, 12), Labels Shape: (2,)\n",
      "Leaf Node 2: Leaf node 1.1.2 (87 samples), Samples Shape: (89, 12, 12, 12), Labels Shape: (89,)\n",
      "Leaf Node 3: Leaf node 1.2.1 (8 samples), Samples Shape: (8, 12, 12, 12), Labels Shape: (8,)\n",
      "Leaf Node 4: Leaf node 1.2.2 (68 samples), Samples Shape: (67, 12, 12, 12), Labels Shape: (67,)\n",
      "Leaf Node 5: Leaf node 2.1.1 (106 samples), Samples Shape: (106, 12, 12, 12), Labels Shape: (106,)\n",
      "Leaf Node 6: Leaf node 2.1.2 (37 samples), Samples Shape: (36, 12, 12, 12), Labels Shape: (36,)\n",
      "Leaf Node 7: Leaf node 2.2.1 (7 samples), Samples Shape: (7, 12, 12, 12), Labels Shape: (7,)\n",
      "Leaf Node 8: Leaf node 2.2.2 (5 samples), Samples Shape: (5, 12, 12, 12), Labels Shape: (5,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(lmci_tensor, lmci_y, test_size=0.2, random_state=42)\n",
    "X_coarsen_shape = (1,4,4,4)\n",
    "X_coarsen_func = np.mean\n",
    "X_train = block_reduce(X_train,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_test = block_reduce(X_test,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_train = X_train+np.random.randn(*X_train.shape) * 1e-3\n",
    "\n",
    "# Initialize a list to hold the smaller tensors for each leaf node\n",
    "leaf_nodes = []\n",
    "\n",
    "# Condition 1: X[:, 7, 5, 3] <= 1.7269168438613414\n",
    "mask_1 = X_train[:, 7, 5, 3] <= 1.7269168438613414\n",
    "\n",
    "# Sub-condition 1.1: X[:, 4, 7, 8] <= 0.0698931760378182\n",
    "mask_1_1 = mask_1 & (X_train[:, 4, 7, 8] <= 0.0698931760378182)\n",
    "\n",
    "# Sub-condition 1.1.1: X[:, 4, 8, 9] <= 0.03768671287596226 (leaf node, 2 samples)\n",
    "mask_1_1_1 = mask_1_1 & (X_train[:, 4, 8, 9] <= 0.03768671287596226)\n",
    "leaf_nodes.append({\n",
    "    'samples': X_train[mask_1_1_1],\n",
    "    'labels': y_train[mask_1_1_1],\n",
    "    'description': 'Leaf node 1.1.1 (2 samples)'\n",
    "})\n",
    "\n",
    "# Sub-condition 1.1.2: X[:, 4, 8, 9] > 0.03768671287596226 (leaf node, 87 samples)\n",
    "mask_1_1_2 = mask_1_1 & (X_train[:, 4, 8, 9] > 0.03768671287596226)\n",
    "leaf_nodes.append({\n",
    "    'samples': X_train[mask_1_1_2],\n",
    "    'labels': y_train[mask_1_1_2],\n",
    "    'description': 'Leaf node 1.1.2 (87 samples)'\n",
    "})\n",
    "\n",
    "# Sub-condition 1.2: X[:, 4, 7, 8] > 0.0698931760378182\n",
    "mask_1_2 = mask_1 & (X_train[:, 4, 7, 8] > 0.0698931760378182)\n",
    "\n",
    "# Sub-condition 1.2.1: X[:, 10, 7, 3] <= 0.8018943796157837 (leaf node, 8 samples)\n",
    "mask_1_2_1 = mask_1_2 & (X_train[:, 10, 7, 3] <= 0.8018943796157837)\n",
    "leaf_nodes.append({\n",
    "    'samples': X_train[mask_1_2_1],\n",
    "    'labels': y_train[mask_1_2_1],\n",
    "    'description': 'Leaf node 1.2.1 (8 samples)'\n",
    "})\n",
    "\n",
    "# Sub-condition 1.2.2: X[:, 10, 7, 3] > 0.8018943796157837 (leaf node, 68 samples)\n",
    "mask_1_2_2 = mask_1_2 & (X_train[:, 10, 7, 3] > 0.8018943796157837)\n",
    "leaf_nodes.append({\n",
    "    'samples': X_train[mask_1_2_2],\n",
    "    'labels': y_train[mask_1_2_2],\n",
    "    'description': 'Leaf node 1.2.2 (68 samples)'\n",
    "})\n",
    "\n",
    "# Condition 2: X[:, 7, 5, 3] > 1.7269168438613414\n",
    "mask_2 = X_train[:, 7, 5, 3] > 1.7269168438613414\n",
    "\n",
    "# Sub-condition 2.1: X[:, 8, 7, 1] <= 3.0189043784737586\n",
    "mask_2_1 = mask_2 & (X_train[:, 8, 7, 1] <= 3.0189043784737586)\n",
    "\n",
    "# Sub-condition 2.1.1: X[:, 5, 6, 8] <= 0.35621589033305645 (leaf node, 106 samples)\n",
    "mask_2_1_1 = mask_2_1 & (X_train[:, 5, 6, 8] <= 0.35621589033305645)\n",
    "leaf_nodes.append({\n",
    "    'samples': X_train[mask_2_1_1],\n",
    "    'labels': y_train[mask_2_1_1],\n",
    "    'description': 'Leaf node 2.1.1 (106 samples)'\n",
    "})\n",
    "\n",
    "# Sub-condition 2.1.2: X[:, 5, 6, 8] > 0.35621589033305645 (leaf node, 37 samples)\n",
    "mask_2_1_2 = mask_2_1 & (X_train[:, 5, 6, 8] > 0.35621589033305645)\n",
    "leaf_nodes.append({\n",
    "    'samples': X_train[mask_2_1_2],\n",
    "    'labels': y_train[mask_2_1_2],\n",
    "    'description': 'Leaf node 2.1.2 (37 samples)'\n",
    "})\n",
    "\n",
    "# Sub-condition 2.2: X[:, 8, 7, 1] > 3.0189043784737586\n",
    "mask_2_2 = mask_2 & (X_train[:, 8, 7, 1] > 3.0189043784737586)\n",
    "\n",
    "# Sub-condition 2.2.1: X[:, 7, 5, 8] <= 3.9584479460716246 (leaf node, 7 samples)\n",
    "mask_2_2_1 = mask_2_2 & (X_train[:, 7, 5, 8] <= 3.9584479460716246)\n",
    "leaf_nodes.append({\n",
    "    'samples': X_train[mask_2_2_1],\n",
    "    'labels': y_train[mask_2_2_1],\n",
    "    'description': 'Leaf node 2.2.1 (7 samples)'\n",
    "})\n",
    "\n",
    "# Sub-condition 2.2.2: X[:, 7, 5, 8] > 3.9584479460716246 (leaf node, 5 samples)\n",
    "mask_2_2_2 = mask_2_2 & (X_train[:, 7, 5, 8] > 3.9584479460716246)\n",
    "leaf_nodes.append({\n",
    "    'samples': X_train[mask_2_2_2],\n",
    "    'labels': y_train[mask_2_2_2],\n",
    "    'description': 'Leaf node 2.2.2 (5 samples)'\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "for i, node in enumerate(leaf_nodes):\n",
    "    print(f\"Leaf Node {i+1}: {node['description']}, Samples Shape: {node['samples'].shape}, Labels Shape: {node['labels'].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping leaf node 1, as it has only 2 samples.\n",
      "Training model for leaf node 2, with 89 samples\n",
      "Time out: 13.256395101547241\n",
      "Model trained for leaf node 2. Beta_est shape: (12, 12, 12)\n",
      "Skipping leaf node 3, as it has only 8 samples.\n",
      "Training model for leaf node 4, with 67 samples\n",
      "Time out: 11.7952880859375\n",
      "Model trained for leaf node 4. Beta_est shape: (12, 12, 12)\n",
      "Training model for leaf node 5, with 106 samples\n",
      "Time out: 14.045124053955078\n",
      "Model trained for leaf node 5. Beta_est shape: (12, 12, 12)\n",
      "Training model for leaf node 6, with 36 samples\n",
      "Time out: 10.121175050735474\n",
      "Model trained for leaf node 6. Beta_est shape: (12, 12, 12)\n",
      "Skipping leaf node 7, as it has only 7 samples.\n",
      "Skipping leaf node 8, as it has only 5 samples.\n",
      "Leaf node 2 - Beta_est shape: (12, 12, 12), sample size: 89\n",
      "Leaf node 4 - Beta_est shape: (12, 12, 12), sample size: 67\n",
      "Leaf node 5 - Beta_est shape: (12, 12, 12), sample size: 106\n",
      "Leaf node 6 - Beta_est shape: (12, 12, 12), sample size: 36\n"
     ]
    }
   ],
   "source": [
    "# Parameters for tensor regression\n",
    "nsweep = 100\n",
    "rank = 6\n",
    "burn = 0.3\n",
    "nskip = 1\n",
    "nsamp = int(np.floor((1 - burn) * nsweep / nskip))\n",
    "ss = np.ceil(np.linspace(burn, 1, nsamp) * nsweep).astype(int) - 1  # adjust for 0-based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping leaf node 1, as it has only 2 samples.\n",
      "Training model for leaf node 2, with 89 samples\n",
      "Time out: 13.267109870910645\n",
      "Model trained for leaf node 2. RMSE: 0.8273919683399161\n",
      "Skipping leaf node 3, as it has only 8 samples.\n",
      "Training model for leaf node 4, with 67 samples\n",
      "Time out: 11.872551202774048\n",
      "Model trained for leaf node 4. RMSE: 1.177367175140335\n",
      "Training model for leaf node 5, with 106 samples\n",
      "Time out: 14.63814663887024\n",
      "Model trained for leaf node 5. RMSE: 0.7866168291767057\n",
      "Training model for leaf node 6, with 36 samples\n",
      "Time out: 10.018769264221191\n",
      "Model trained for leaf node 6. RMSE: 2.0979832028686918\n",
      "Skipping leaf node 7, as it has only 7 samples.\n",
      "Skipping leaf node 8, as it has only 5 samples.\n",
      "Leaf node 2 - RMSE: 0.8273919683399161, sample size: 89\n",
      "Leaf node 4 - RMSE: 1.177367175140335, sample size: 67\n",
      "Leaf node 5 - RMSE: 0.7866168291767057, sample size: 106\n",
      "Leaf node 6 - RMSE: 2.0979832028686918, sample size: 36\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results, including errors\n",
    "results = []\n",
    "\n",
    "for i, node in enumerate(leaf_nodes):\n",
    "    # Check if the sample size is greater than 10\n",
    "    if node['samples'].shape[0] > 10:\n",
    "        print(f\"Training model for leaf node {i+1}, with {node['samples'].shape[0]} samples\")\n",
    "\n",
    "        # z_train is an array of zeros with length equal to the number of samples\n",
    "        z_train = np.zeros((node['samples'].shape[0], 1))  # Zero-filled array for z_train\n",
    "        X_train = node['samples']  # Replace this with the appropriate tensor feature data\n",
    "        y_train = node['labels']\n",
    "\n",
    "        # Run tensor_reg for this leaf node\n",
    "        out = tensor_reg(\n",
    "            z_train=z_train, \n",
    "            x_train=X_train, \n",
    "            y_train=y_train, \n",
    "            nsweep=nsweep, \n",
    "            rank=rank, \n",
    "            burn=burn, \n",
    "            nskip=nskip, \n",
    "            scale=True, \n",
    "            a_lam=None, \n",
    "            b_lam=None, \n",
    "            phi_alpha=None, \n",
    "            plot=True\n",
    "        )\n",
    "\n",
    "        # Compute Beta_mcmc\n",
    "        Beta_mcmc = getBeta_mcmc(out['beta_store'])\n",
    "\n",
    "        # Compute Beta_est\n",
    "        p = [out[\"beta_store\"][0][x].shape[1] for x in range(len(out[\"beta_store\"][0]))]\n",
    "        Beta_est = (out['sy'] / out['sx']) * np.mean(Beta_mcmc[ss, :], axis=0).reshape(p)\n",
    "\n",
    "        # Calculate relative error (RMSE) for this node\n",
    "        err = 0\n",
    "        for j in range(X_train.shape[0]):\n",
    "            err += (np.tensordot(X_train[j], Beta_est, axes=((0, 1, 2), (0, 1, 2))) - y_train[j]) ** 2\n",
    "        mse = err / X_train.shape[0]\n",
    "        rmse = np.sqrt(mse) / np.var(y_train)\n",
    "\n",
    "        # Store the result for this node, including the RMSE\n",
    "        results.append({\n",
    "            'leaf_node': i + 1,\n",
    "            'Beta_mcmc': Beta_mcmc,\n",
    "            'Beta_est': Beta_est,\n",
    "            'rmse': rmse,\n",
    "            'sample_size': node['samples'].shape[0]\n",
    "        })\n",
    "\n",
    "        print(f\"Model trained for leaf node {i+1}. RMSE: {rmse}\")\n",
    "    else:\n",
    "        print(f\"Skipping leaf node {i+1}, as it has only {node['samples'].shape[0]} samples.\")\n",
    "\n",
    "# After the loop, you can access the results for each node\n",
    "for result in results:\n",
    "    print(f\"Leaf node {result['leaf_node']} - RMSE: {result['rmse']}, sample size: {result['sample_size']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Leaf Node 1: Test Leaf node 1.1.1, Samples Shape: (0, 12, 12, 12), Labels Shape: (0,)\n",
      "Test Leaf Node 2: Test Leaf node 1.1.2, Samples Shape: (23, 12, 12, 12), Labels Shape: (23,)\n",
      "Test Leaf Node 3: Test Leaf node 1.2.1, Samples Shape: (2, 12, 12, 12), Labels Shape: (2,)\n",
      "Test Leaf Node 4: Test Leaf node 1.2.2, Samples Shape: (16, 12, 12, 12), Labels Shape: (16,)\n",
      "Test Leaf Node 5: Test Leaf node 2.1.1, Samples Shape: (28, 12, 12, 12), Labels Shape: (28,)\n",
      "Test Leaf Node 6: Test Leaf node 2.1.2, Samples Shape: (7, 12, 12, 12), Labels Shape: (7,)\n",
      "Test Leaf Node 7: Test Leaf node 2.2.1, Samples Shape: (3, 12, 12, 12), Labels Shape: (3,)\n",
      "Test Leaf Node 8: Test Leaf node 2.2.2, Samples Shape: (2, 12, 12, 12), Labels Shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to hold the smaller tensors for each leaf node in the test set\n",
    "test_leaf_nodes = []\n",
    "\n",
    "# Condition 1: X_test[:, 7, 5, 3] <= 1.7269168438613414\n",
    "mask_1_test = X_test[:, 7, 5, 3] <= 1.7269168438613414\n",
    "\n",
    "# Sub-condition 1.1: X_test[:, 4, 7, 8] <= 0.0698931760378182\n",
    "mask_1_1_test = mask_1_test & (X_test[:, 4, 7, 8] <= 0.0698931760378182)\n",
    "\n",
    "# Sub-condition 1.1.1: X_test[:, 4, 8, 9] <= 0.03768671287596226 (leaf node, 2 samples)\n",
    "mask_1_1_1_test = mask_1_1_test & (X_test[:, 4, 8, 9] <= 0.03768671287596226)\n",
    "test_leaf_nodes.append({\n",
    "    'samples': X_test[mask_1_1_1_test],\n",
    "    'labels': y_test[mask_1_1_1_test],\n",
    "    'description': 'Test Leaf node 1.1.1'\n",
    "})\n",
    "\n",
    "# Sub-condition 1.1.2: X_test[:, 4, 8, 9] > 0.03768671287596226 (leaf node, 87 samples)\n",
    "mask_1_1_2_test = mask_1_1_test & (X_test[:, 4, 8, 9] > 0.03768671287596226)\n",
    "test_leaf_nodes.append({\n",
    "    'samples': X_test[mask_1_1_2_test],\n",
    "    'labels': y_test[mask_1_1_2_test],\n",
    "    'description': 'Test Leaf node 1.1.2'\n",
    "})\n",
    "\n",
    "# Sub-condition 1.2: X_test[:, 4, 7, 8] > 0.0698931760378182\n",
    "mask_1_2_test = mask_1_test & (X_test[:, 4, 7, 8] > 0.0698931760378182)\n",
    "\n",
    "# Sub-condition 1.2.1: X_test[:, 10, 7, 3] <= 0.8018943796157837 (leaf node, 8 samples)\n",
    "mask_1_2_1_test = mask_1_2_test & (X_test[:, 10, 7, 3] <= 0.8018943796157837)\n",
    "test_leaf_nodes.append({\n",
    "    'samples': X_test[mask_1_2_1_test],\n",
    "    'labels': y_test[mask_1_2_1_test],\n",
    "    'description': 'Test Leaf node 1.2.1'\n",
    "})\n",
    "\n",
    "# Sub-condition 1.2.2: X_test[:, 10, 7, 3] > 0.8018943796157837 (leaf node, 68 samples)\n",
    "mask_1_2_2_test = mask_1_2_test & (X_test[:, 10, 7, 3] > 0.8018943796157837)\n",
    "test_leaf_nodes.append({\n",
    "    'samples': X_test[mask_1_2_2_test],\n",
    "    'labels': y_test[mask_1_2_2_test],\n",
    "    'description': 'Test Leaf node 1.2.2'\n",
    "})\n",
    "\n",
    "# Condition 2: X_test[:, 7, 5, 3] > 1.7269168438613414\n",
    "mask_2_test = X_test[:, 7, 5, 3] > 1.7269168438613414\n",
    "\n",
    "# Sub-condition 2.1: X_test[:, 8, 7, 1] <= 3.0189043784737586\n",
    "mask_2_1_test = mask_2_test & (X_test[:, 8, 7, 1] <= 3.0189043784737586)\n",
    "\n",
    "# Sub-condition 2.1.1: X_test[:, 5, 6, 8] <= 0.35621589033305645 (leaf node, 106 samples)\n",
    "mask_2_1_1_test = mask_2_1_test & (X_test[:, 5, 6, 8] <= 0.35621589033305645)\n",
    "test_leaf_nodes.append({\n",
    "    'samples': X_test[mask_2_1_1_test],\n",
    "    'labels': y_test[mask_2_1_1_test],\n",
    "    'description': 'Test Leaf node 2.1.1'\n",
    "})\n",
    "\n",
    "# Sub-condition 2.1.2: X_test[:, 5, 6, 8] > 0.35621589033305645 (leaf node, 37 samples)\n",
    "mask_2_1_2_test = mask_2_1_test & (X_test[:, 5, 6, 8] > 0.35621589033305645)\n",
    "test_leaf_nodes.append({\n",
    "    'samples': X_test[mask_2_1_2_test],\n",
    "    'labels': y_test[mask_2_1_2_test],\n",
    "    'description': 'Test Leaf node 2.1.2'\n",
    "})\n",
    "\n",
    "# Sub-condition 2.2: X_test[:, 8, 7, 1] > 3.0189043784737586\n",
    "mask_2_2_test = mask_2_test & (X_test[:, 8, 7, 1] > 3.0189043784737586)\n",
    "\n",
    "# Sub-condition 2.2.1: X_test[:, 7, 5, 8] <= 3.9584479460716246 (leaf node, 7 samples)\n",
    "mask_2_2_1_test = mask_2_2_test & (X_test[:, 7, 5, 8] <= 3.9584479460716246)\n",
    "test_leaf_nodes.append({\n",
    "    'samples': X_test[mask_2_2_1_test],\n",
    "    'labels': y_test[mask_2_2_1_test],\n",
    "    'description': 'Test Leaf node 2.2.1'\n",
    "})\n",
    "\n",
    "# Sub-condition 2.2.2: X_test[:, 7, 5, 8] > 3.9584479460716246 (leaf node, 5 samples)\n",
    "mask_2_2_2_test = mask_2_2_test & (X_test[:, 7, 5, 8] > 3.9584479460716246)\n",
    "test_leaf_nodes.append({\n",
    "    'samples': X_test[mask_2_2_2_test],\n",
    "    'labels': y_test[mask_2_2_2_test],\n",
    "    'description': 'Test Leaf node 2.2.2'\n",
    "})\n",
    "\n",
    "# Display the results for test set\n",
    "for i, node in enumerate(test_leaf_nodes):\n",
    "    print(f\"Test Leaf Node {i+1}: {node['description']}, Samples Shape: {node['samples'].shape}, Labels Shape: {node['labels'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE for leaf node 2: nan\n",
      "Test RMSE for leaf node 4: 0.8814856696292109\n",
      "Test RMSE for leaf node 5: 2.789346666898399\n",
      "Test RMSE for leaf node 6: 2.0303151451868158\n",
      "Test Leaf node 2 - Test RMSE: nan, sample size: 0\n",
      "Test Leaf node 4 - Test RMSE: 0.8814856696292109, sample size: 23\n",
      "Test Leaf node 5 - Test RMSE: 2.789346666898399, sample size: 2\n",
      "Test Leaf node 6 - Test RMSE: 2.0303151451868158, sample size: 16\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store test results, including errors\n",
    "test_results = []\n",
    "\n",
    "# Loop through the results from the training phase and apply them to the test data\n",
    "for i, result in enumerate(results):\n",
    "    # Find the corresponding test node (assuming the order matches between train and test)\n",
    "    test_node = test_leaf_nodes[i]\n",
    "\n",
    "    # Use the Beta_est from training\n",
    "    Beta_est = result['Beta_est']\n",
    "    X_test = test_node['samples']  # Test samples for the corresponding node\n",
    "    y_test = test_node['labels']   # Test labels for the corresponding node\n",
    "\n",
    "    # Calculate predicted values and relative error (RMSE) for this test node\n",
    "    err = 0\n",
    "    for j in range(X_test.shape[0]):\n",
    "        predicted_value = np.tensordot(X_test[j], Beta_est, axes=((0, 1, 2), (0, 1, 2)))\n",
    "        err += (predicted_value - y_test[j]) ** 2\n",
    "    mse = err / X_test.shape[0] if X_test.shape[0] > 0 else np.nan  # Handle case with no samples\n",
    "    rmse = np.sqrt(mse) / np.var(y_test) if np.var(y_test) > 0 else np.nan  # Handle variance edge cases\n",
    "\n",
    "    # Store the test result, including the RMSE\n",
    "    test_results.append({\n",
    "        'leaf_node': result['leaf_node'],\n",
    "        'rmse': rmse,\n",
    "        'sample_size': X_test.shape[0]\n",
    "    })\n",
    "\n",
    "    print(f\"Test RMSE for leaf node {result['leaf_node']}: {rmse}\")\n",
    "\n",
    "# After the loop, you can access the results for each test node\n",
    "for test_result in test_results:\n",
    "    print(f\"Test Leaf node {test_result['leaf_node']} - Test RMSE: {test_result['rmse']}, sample size: {test_result['sample_size']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 48, 48, 48) (320,)\n",
      "(320, 12, 12, 12) (320,) (81, 12, 12, 12)\n",
      "mean train RSE:  0.9963371152213625\n",
      "CP train RSE:  0.9962944858192141\n",
      "Tucker train RSE:  0.9962933128414942\n",
      "mean test RSE:  0.8856632351504014\n",
      "CP test RSE:  7.177569757735098\n",
      "Tucker test RSE:  7.177630256588527\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lmci_tensor, lmci_y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "model  =  TensorDecisionTreeRegressor(max_depth=3, min_samples_split=12,split_method='variance_LS', split_rank=4, CP_reg_rank=12, Tucker_reg_rank=12, n_mode=3)\n",
    "model.use_mean_as_threshold  =  False\n",
    "model.sample_rate  =  .5\n",
    "X_coarsen_shape = (1,4,4,4)\n",
    "X_coarsen_func = np.min\n",
    "X_train_c = block_reduce(X_train,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_test_c = block_reduce(X_test,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "#middle_z = X_train_c.shape[2] // 2\n",
    "#X_train_c = X_train_c[:,:,:,middle_z:middle_z+2]\n",
    "#X_test_c = X_test_c[:,:,:,middle_z:middle_z+2]\n",
    "X_train_c = X_train_c+np.ones_like(X_train_c)*1e-3\n",
    "print(X_train_c.shape,y_train.shape,X_test_c.shape)\n",
    "model.fit(X_train_c,y_train)\n",
    "\n",
    "predictions = model.predict(X_train_c,regression_method='mean')\n",
    "print(f\"mean train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_train_c,regression_method='cp')\n",
    "print(f\"CP train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_train_c,regression_method='tucker')\n",
    "print(f\"Tucker train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train)) \n",
    "\n",
    "predictions = model.predict(X_test_c,regression_method='mean')\n",
    "print(f\"mean test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_test_c,regression_method='cp')\n",
    "print(f\"CP test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_test_c,regression_method='tucker')\n",
    "print(f\"Tucker test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 48, 48, 48) (320,)\n",
      "(320, 12, 12, 12) (320,) (81, 12, 12, 12)\n",
      "mean train RSE:  0.6661496723911483\n",
      "CP train RSE:  3.4349786378264703e-05\n",
      "Tucker train RSE:  2.0667959953642558e-05\n",
      "mean test RSE:  1.1896976580496539\n",
      "CP test RSE:  2.255613223889068\n",
      "Tucker test RSE:  2.1889356342403525\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lmci_tensor, lmci_y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "model  =  TensorDecisionTreeRegressor(max_depth=3, min_samples_split=12,split_method='variance_LS', split_rank=4, CP_reg_rank=12, Tucker_reg_rank=12, n_mode=3)\n",
    "model.use_mean_as_threshold  =  False\n",
    "model.sample_rate  =  .5\n",
    "X_coarsen_shape = (1,4,4,4)\n",
    "X_coarsen_func = np.sum\n",
    "X_train_c = block_reduce(X_train,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_test_c = block_reduce(X_test,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "#middle_z = X_train_c.shape[2] // 2\n",
    "#X_train_c = X_train_c[:,:,:,middle_z:middle_z+2]\n",
    "#X_test_c = X_test_c[:,:,:,middle_z:middle_z+2]\n",
    "X_train_c = X_train_c+np.ones_like(X_train_c)*1e-3\n",
    "print(X_train_c.shape,y_train.shape,X_test_c.shape)\n",
    "model.fit(X_train_c,y_train)\n",
    "\n",
    "predictions = model.predict(X_train_c,regression_method='mean')\n",
    "print(f\"mean train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_train_c,regression_method='cp')\n",
    "print(f\"CP train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_train_c,regression_method='tucker')\n",
    "print(f\"Tucker train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train)) \n",
    "\n",
    "predictions = model.predict(X_test_c,regression_method='mean')\n",
    "print(f\"mean test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_test_c,regression_method='cp')\n",
    "print(f\"CP test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_test_c,regression_method='tucker')\n",
    "print(f\"Tucker test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 48, 48, 48) (320,)\n",
      "(320, 12, 12, 12) (320,) (81, 12, 12, 12)\n",
      "mean train RSE:  0.7098757202280661\n",
      "CP train RSE:  0.00017612500428918927\n",
      "Tucker train RSE:  8.283606482577344e-05\n",
      "mean test RSE:  1.065739198206284\n",
      "CP test RSE:  2.3129099613767967\n",
      "Tucker test RSE:  2.2532195918751357\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lmci_tensor, lmci_y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "model  =  TensorDecisionTreeRegressor(max_depth=3, min_samples_split=12,split_method='variance_LS', split_rank=4, CP_reg_rank=12, Tucker_reg_rank=12, n_mode=3)\n",
    "model.use_mean_as_threshold  =  False\n",
    "model.sample_rate  =  .5\n",
    "X_coarsen_shape = (1,4,4,4)\n",
    "X_coarsen_func = np.median\n",
    "X_train_c = block_reduce(X_train,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_test_c = block_reduce(X_test,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "#middle_z = X_train_c.shape[2] // 2\n",
    "#X_train_c = X_train_c[:,:,:,middle_z:middle_z+2]\n",
    "#X_test_c = X_test_c[:,:,:,middle_z:middle_z+2]\n",
    "X_train_c = X_train_c+np.ones_like(X_train_c)*1e-3\n",
    "print(X_train_c.shape,y_train.shape,X_test_c.shape)\n",
    "model.fit(X_train_c,y_train)\n",
    "\n",
    "predictions = model.predict(X_train_c,regression_method='mean')\n",
    "print(f\"mean train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_train_c,regression_method='cp')\n",
    "print(f\"CP train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_train_c,regression_method='tucker')\n",
    "print(f\"Tucker train RSE: \", np.mean((predictions-y_train)**2)/np.var(y_train)) \n",
    "\n",
    "predictions = model.predict(X_test_c,regression_method='mean')\n",
    "print(f\"mean test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_test_c,regression_method='cp')\n",
    "print(f\"CP test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))\n",
    "predictions = model.predict(X_test_c,regression_method='tucker')\n",
    "print(f\"Tucker test RSE: \", np.mean((predictions-y_test)**2)/np.var(y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
