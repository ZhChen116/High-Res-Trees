{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping PTID '013_S_0699' because y_value is NaN.\n",
      "Aligned image tensor shape: (817, 48, 48, 48)\n",
      "Aligned y variable shape: (817,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "# sliced 3D real image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorly as tl\n",
    "\n",
    "#Debugging import\n",
    "import importlib\n",
    "var = 'TensorDecisionTreeRegressorP' #the published version of code\n",
    "package = importlib.import_module(var)\n",
    "for name, value in package.__dict__.items():\n",
    "    if not name.startswith(\"__\"):\n",
    "        globals()[name] = value\n",
    "\n",
    "from TensorDecisionTreeRegressorP import *\n",
    "\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV file containing PTID and target variable\n",
    "csv_file = '/Users/zc56/Documents/CommenDesktop/RICE/MyProject/Bayes_Tensor_Tree/3D-images/ADNIData.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Extract PTID and target values from the DataFrame\n",
    "ptid_csv = df['PTID'].values\n",
    "y_variable = df['ADAS11'].values\n",
    "\n",
    "# Directory containing the image files\n",
    "directory = '/Users/zc56/Documents/CommenDesktop/RICE/MyProject/Bayes_Tensor_Tree/3D-images/3D-Images/bl'\n",
    "\n",
    "# Initialize lists for storing matched images and corresponding y values\n",
    "matched_images = []\n",
    "matched_y_values = []\n",
    "\n",
    "# Loop through the image files and match by PTID\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.nii.gz'):\n",
    "        # Extract PTID from the filename (e.g., '002_S_0295.nii.gz' -> '002_S_0295')\n",
    "        ptid_image = filename.split('.')[0]  # Keep the '002_S_0295' format with underscores\n",
    "        \n",
    "        # Find the index of this PTID in the CSV data\n",
    "        if ptid_image in ptid_csv:\n",
    "            index = np.where(ptid_csv == ptid_image)[0][0]  # Get the index of the matching PTID\n",
    "            y_value = y_variable[index]  # Get the corresponding target value\n",
    "\n",
    "            # Skip if the corresponding y_value is NaN\n",
    "            if np.isnan(y_value):\n",
    "                print(f\"Skipping PTID '{ptid_image}' because y_value is NaN.\")\n",
    "                continue\n",
    "\n",
    "            # Load the image\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            img = nib.load(file_path)\n",
    "            data = img.get_fdata()\n",
    "\n",
    "            # Append the image data and the corresponding y_value to the lists\n",
    "            matched_images.append(data)\n",
    "            matched_y_values.append(y_value)\n",
    "        else:\n",
    "            print(f\"PTID '{ptid_image}' not found in the CSV file.\")\n",
    "\n",
    "# Convert the matched images and y values into arrays\n",
    "if matched_images:\n",
    "    image_tensor = np.stack(matched_images, axis=0)\n",
    "    y_variable = np.array(matched_y_values)\n",
    "    print(f\"Aligned image tensor shape: {image_tensor.shape}\")\n",
    "    print(f\"Aligned y variable shape: {y_variable.shape}\")\n",
    "else:\n",
    "    print(\"No images matched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1 y-values: [14.33 21.67 20.33 13.33 12.67 16.67 32.33 18.33 16.   20.   13.    9.67\n",
      "  9.   19.   35.33 18.   11.33  5.    8.    9.33 16.67 12.33 24.   15.33\n",
      " 22.   15.   15.67 19.67 14.   14.67 22.   15.   18.   27.67 14.67  7.33\n",
      "  7.67  6.33 21.33 26.67 11.   24.   15.33 18.67 14.67 11.    9.67 11.33\n",
      " 21.67 11.67 24.67 17.67 10.   17.   28.   19.    9.67 14.   24.   14.67\n",
      " 36.   13.   14.33 22.   22.33 10.67  9.67 14.67 19.33 18.67 24.67 42.67\n",
      " 15.67 16.67 10.67 23.   19.33 11.33 10.33 13.67 35.33 12.   12.33 21.33\n",
      " 12.   17.67 20.   24.    6.67 18.67 15.33  9.33 19.67]\n",
      "Group 2 y-values: [23.    9.33 10.67  1.67 12.   17.33 25.33  8.67 20.   17.67 25.    6.\n",
      " 14.33 14.67  9.    3.   14.67 11.67 21.   16.    7.33 16.    6.67 18.\n",
      " 10.   11.33  9.   28.    5.   26.67 11.   10.67 13.33  8.67 11.67 19.67\n",
      " 11.33  5.   13.33  4.   21.33  5.33  7.67 10.67 16.   18.33 13.33 10.\n",
      " 10.67  7.33 20.67 33.   11.67  9.    7.67 30.33 17.33  4.33  8.67 22.33\n",
      " 11.67 12.33 26.67 11.33  8.67 15.67 13.   14.    8.67 12.67  2.   26.67\n",
      " 22.   11.33 11.33  9.67 23.   15.67 13.   17.67 12.    8.   20.33  1.67\n",
      "  5.67  5.33 13.67 21.33 10.   15.33  8.67 10.33  7.   10.67 10.33 11.\n",
      "  5.   24.   16.33  9.33  9.33 11.67 14.67 16.33 15.   17.33 15.   13.67\n",
      " 11.67  7.33 13.67 15.33 11.33 16.67 19.    4.   15.33  6.33 16.   20.33\n",
      "  4.33 18.   18.33  9.67 15.33 11.   15.33  4.    9.  ]\n",
      "Group 3 y-values: [ 3.33  7.67 14.33 14.   22.33  4.33  6.   29.33 14.   18.67  8.67  9.33\n",
      " 10.    5.67 12.   12.67  5.67 17.   21.    6.    7.33  5.33  8.33 10.67\n",
      " 18.33  6.   10.67 20.    7.67 17.    3.67  5.67  8.    7.67  9.67 17.\n",
      "  6.    8.    3.    8.   10.   10.   19.33 14.33 17.   35.   12.   10.33\n",
      "  6.   13.33 18.33  6.33 14.   12.33  8.33 20.33  6.    5.33 18.   11.33\n",
      " 10.67  3.33  9.   15.33 23.    5.    9.   14.   13.67 10.67 12.    5.\n",
      "  7.67 10.67 18.67  3.67 11.33 14.33 10.    9.33 10.   18.67 34.33 16.\n",
      " 11.67  9.33 15.   12.    9.67 12.   11.67  7.67 14.    7.33  1.33 13.33\n",
      " 14.33 10.67  9.67 12.   16.   15.67 13.67  4.   16.    5.33  4.   12.67\n",
      "  8.    8.   21.    7.   14.33 13.67 12.67  7.33 21.   13.67]\n",
      "Group 4 y-values: [10.67 14.33  8.67  7.    3.67  3.    9.67  9.67  8.    7.67  7.    2.33\n",
      " 11.67 11.67 10.    3.33  6.    7.67 17.33  6.   10.67 11.33  9.67 17.33\n",
      " 13.33  3.33  7.33  4.   10.    3.33  8.33  4.67  9.33  3.    4.33  8.33\n",
      " 14.   10.33 17.33  3.67  6.67  6.67 16.33  4.33  3.    6.33 14.33 11.\n",
      " 12.    9.67 17.67  6.33 18.67 14.33  2.67  5.   17.67  5.    4.    8.33\n",
      " 10.67 17.    2.33  4.   15.33  6.    3.33  9.   16.33  8.    6.   14.33\n",
      " 10.33  8.33  4.    7.67  6.67  3.    6.67 11.67  9.    9.67  6.33 10.\n",
      " 16.33 10.67 18.   10.    3.33  6.33  6.33  2.    3.    8.    5.    5.33\n",
      " 14.33 11.33 13.67  2.33  4.33  6.   13.33  9.33  9.   13.67 11.33 17.33\n",
      "  9.33  5.33 11.33 11.   11.67  9.    5.67 12.    3.33 12.    3.   12.\n",
      "  3.    5.67 17.67  5.33  7.33  4.67 11.    7.    8.67  7.33 20.33  5.67\n",
      "  7.33 12.67  9.33  6.67  8.    2.33 11.    7.   12.67  5.    9.67  7.67\n",
      " 10.   10.67  4.33  6.67  2.33  4.   10.   14.33 11.67 13.    5.67 14.\n",
      " 10.67  8.    3.33 12.33 12.   10.    8.    8.67 10.33  8.    8.67  5.67\n",
      "  1.67  3.67  7.    3.    6.33 10.    6.67  9.67 12.67  6.67  5.   10.\n",
      "  7.   10.67 14.33  8.67  4.33  7.67  1.    7.33  5.    4.67 12.33  7.\n",
      "  3.   16.    6.33 13.67  6.67  7.33 13.33  3.67  7.33 14.   11.33  7.33\n",
      " 21.33  8.67  8.67  5.33  5.67  3.67  2.   18.   10.67  6.33  8.    4.33\n",
      "  9.67  2.67 12.33  6.33  3.   21.    6.33  5.67 11.33  6.67  3.33  2.\n",
      " 16.    5.   11.33]\n",
      "Group 1 mean: 16.989569892473117, samples: 93\n",
      "Group 2 mean: 13.188604651162791, samples: 129\n",
      "Group 3 mean: 11.683559322033897, samples: 118\n",
      "Group 4 mean: 8.587142857142858, samples: 231\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example dataset for demonstration\n",
    "# Assuming X is a 4D tensor, y is the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_tensor, y_variable, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 1: Apply conditions and group y based on each leaf node\n",
    "\n",
    "# Initialize lists for each group\n",
    "group_1_y = []\n",
    "group_2_y = []\n",
    "group_3_y = []\n",
    "group_4_y = []\n",
    "\n",
    "# Condition checks\n",
    "# Leaf Node 1\n",
    "indices_1 = (X_train[:, 32, 19, 34] <= 3.8721486171364994) & (X_train[:, 28, 20, 18] <= 2.165013522178203)\n",
    "group_1_y = y_train[indices_1]\n",
    "\n",
    "# Leaf Node 2\n",
    "indices_2 = (X_train[:, 32, 19, 34] <= 3.8721486171364994) & (X_train[:, 28, 20, 18] > 2.165013522178203)\n",
    "group_2_y = y_train[indices_2]\n",
    "\n",
    "# Leaf Node 3\n",
    "indices_3 = (X_train[:, 32, 19, 34] > 3.8721486171364994) & (X_train[:, 32, 26, 37] <= 4.602050602265279)\n",
    "group_3_y = y_train[indices_3]\n",
    "\n",
    "# Leaf Node 4\n",
    "indices_4 = (X_train[:, 32, 19, 34] > 3.8721486171364994) & (X_train[:, 32, 26, 37] > 4.602050602265279)\n",
    "group_4_y = y_train[indices_4]\n",
    "\n",
    "# Step 2: Display the grouped y-values for each leaf node\n",
    "print(f\"Group 1 y-values: {group_1_y}\")\n",
    "print(f\"Group 2 y-values: {group_2_y}\")\n",
    "print(f\"Group 3 y-values: {group_3_y}\")\n",
    "print(f\"Group 4 y-values: {group_4_y}\")\n",
    "\n",
    "# Optional: Calculate summary statistics for each group\n",
    "print(f\"Group 1 mean: {np.mean(group_1_y)}, samples: {len(group_1_y)}\")\n",
    "print(f\"Group 2 mean: {np.mean(group_2_y)}, samples: {len(group_2_y)}\")\n",
    "print(f\"Group 3 mean: {np.mean(group_3_y)}, samples: {len(group_3_y)}\")\n",
    "print(f\"Group 4 mean: {np.mean(group_4_y)}, samples: {len(group_4_y)}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot histograms with different colors for each group\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Combined Histogram with transparency\n",
    "plt.hist(group_1_y, bins=15, color='blue', edgecolor='black', alpha=0.5, label=\"Group 1\")\n",
    "plt.hist(group_2_y, bins=15, color='green', edgecolor='black', alpha=0.5, label=\"Group 2\")\n",
    "plt.hist(group_3_y, bins=15, color='orange', edgecolor='black', alpha=0.5, label=\"Group 3\")\n",
    "#plt.hist(group_4_y, bins=15, color='red', edgecolor='black', alpha=0.5, label=\"Group 4\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title(\"Distribution of y for Each Group\")\n",
    "plt.xlabel(\"y values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.linalg import cholesky, inv\n",
    "import math\n",
    "import time\n",
    "from functools import reduce\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.1)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gaussian_kde\n",
    "from scipy.special import gammaln, logsumexp\n",
    "from sklearn.linear_model import LassoCV\n",
    "import itertools\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "from scipy.stats import geninvgauss\n",
    "def getouter_list(bet):\n",
    "    d = len(bet)\n",
    "    if d == 1:\n",
    "        return bet[0]\n",
    "    elif d == 2:\n",
    "        return np.outer(bet[0], bet[1]).reshape(bet[0].shape + bet[1].shape)\n",
    "    else:\n",
    "        return np.outer(getouter_list(bet[:-1]), bet[-1]).reshape(getouter_list(bet[:-1]).shape + bet[-1].shape)\n",
    "\n",
    "def getmean(X, beta, rank, rank_exclude=None):\n",
    "    if rank_exclude is None:\n",
    "        rank_exclude = []\n",
    "\n",
    "    idx = [i for i in range(rank) if i not in rank_exclude]\n",
    "    B_list = [getouter_list([beta_elem[r, :] for beta_elem in beta]) for r in idx]\n",
    "    B = reduce(lambda x, y: x + y, B_list)\n",
    "    def compute_sum(xx, bb):\n",
    "        return np.sum(xx * bb)\n",
    "    mu_B = np.array([compute_sum(xx, B) for xx in X])\n",
    "    return mu_B\n",
    "\n",
    "def logsum(lx):\n",
    "    max_lx = np.max(lx)\n",
    "    return max_lx + np.log(np.sum(np.exp(lx - max_lx)))\n",
    "\n",
    "def TP_rankR(X_allr):\n",
    "    R = X_allr[0].shape[1] if len(X_allr[0].shape) > 1 else None\n",
    "    if R is None:\n",
    "        return getouter_list(X_allr)\n",
    "    else:\n",
    "        dims = [x.shape[0] for x in X_allr]\n",
    "        Y = np.zeros(dims)\n",
    "        for r in range(R):\n",
    "            outer_results = [x[:, r] for x in X_allr]\n",
    "            Y += getouter_list(outer_results)\n",
    "        return Y\n",
    "\n",
    "def getBeta_mcmc(beta_store):\n",
    "    nsweep = len(beta_store)\n",
    "    d = len(beta_store[0])\n",
    "    rank = beta_store[0][0].shape[0]\n",
    "    p = [beta_store[0][x].shape[1] for x in range(d)]\n",
    "    Beta_mcmc = np.zeros((nsweep, np.prod(p)))\n",
    "    \n",
    "    for i in range(nsweep):\n",
    "        coef = np.zeros(np.prod(p))\n",
    "        for r in range(rank):\n",
    "            outer_list = [beta_store[i][x][r, :] for x in range(d)]\n",
    "            coef += getouter_list(outer_list).flatten()\n",
    "        Beta_mcmc[i, :] = coef    \n",
    "    return Beta_mcmc\n",
    "\n",
    "####main function####\n",
    "def tensor_reg(z_train, x_train, y_train, a_lam, b_lam, phi_alpha, nsweep=1e3, rank=5, burn=0.30,\n",
    "               nskip=3, scale=True, plot=False):\n",
    "    \n",
    "    \n",
    "    n = len(y_train)\n",
    "    p = x_train.shape[1:]\n",
    "    d = len(x_train.shape)-1\n",
    "    pgamma = z_train.shape[1]\n",
    "    \n",
    "\n",
    "    #### standarize ####\n",
    "    my = np.mean(y_train)\n",
    "    sy = np.std(y_train, ddof=1) if scale else 1\n",
    "    if scale:\n",
    "        obs = (y_train - my) / sy\n",
    "    else:\n",
    "        obs = y_train\n",
    "    if scale:\n",
    "        mz = np.mean(z_train, axis=0)\n",
    "        sz = np.array([np.max(z_train[:, i]) - np.min(z_train[:, i]) for i in range(pgamma)])\n",
    "        sz[sz==0] = 1\n",
    "        Zt = np.zeros_like(z_train, dtype=float)\n",
    "        for jj in range(pgamma):\n",
    "            Zt[:,jj] = (z_train[:,jj] - mz[jj]) / sz[jj] \n",
    "    \n",
    "        Xt = np.zeros_like(x_train, dtype=float)\n",
    "        mx = np.mean(x_train, axis=0)\n",
    "        def range_diff(z):\n",
    "            return np.nanmax(z) - np.nanmin(z)\n",
    "        sx = np.apply_along_axis(range_diff, axis=0, arr=x_train)\n",
    "        sx[sx == 0] <- 1\n",
    "   \n",
    "        if d == 2:\n",
    "            for jj in range(n):\n",
    "                Xt[jj,:,:] = (x_train[jj,:,:] - mx) / sx\n",
    "        elif d == 3:\n",
    "            for jj in range(n):\n",
    "                Xt[jj,:,:,:] = (x_train[jj,:,:,:] - mx) / sx\n",
    " \n",
    "    else:\n",
    "        Zt = z_train\n",
    "        Xt = x_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    x_train_nona = Xt\n",
    "    #### MCMC setup ####\n",
    "    ZZ = np.dot(Zt.T, Zt)\n",
    "    vecXt = Xt.reshape(n, np.prod(p))\n",
    "    vecXt = np.hstack((z_train, vecXt))\n",
    "\n",
    "\n",
    "    las = LassoCV(cv=5).fit(vecXt, y_train)\n",
    "    beta_init = las.coef_\n",
    "    gam = beta_init[0:pgamma]\n",
    "\n",
    "    ##hyper-par initialize\n",
    "    a_lam = None; b_lam = None; phi_alpha = None\n",
    "    if a_lam is None:\n",
    "        a_lam = [3.0] * rank\n",
    "        a_lam = np.array(a_lam)\n",
    "    if b_lam is None:\n",
    "        b_lam = a_lam**(1/(2*d))\n",
    "    if phi_alpha is None:\n",
    "        phi_alpha = np.array([1/rank]*rank)\n",
    "    phi_a0 = np.sum(phi_alpha)\n",
    "    a_vphi = phi_a0\n",
    "    b_vphi = phi_alpha[1] * rank**(1/d)\n",
    "    c0 = 0\n",
    "    s0 = 1; a_t = 2_5/2; b_t = 2.5/2 * s0**2\n",
    "\n",
    "    ##fix randomness for now\n",
    "    tau2  = 1 / np.random.gamma(size = 1, shape = a_t, scale=1/b_t)\n",
    "    #tau2 = 2\n",
    "    phi = np.random.dirichlet(phi_alpha, size = 1)\n",
    "    varphi = np.random.gamma(size = 1, shape = a_vphi, scale=1/b_vphi)\n",
    "    #varphi = 0.5\n",
    "    tau_r = phi * varphi\n",
    "    # Define the flatten function\n",
    "    def flatten(nested_list):\n",
    "        return [item for sublist in nested_list for item in sublist]\n",
    "    tau_r = flatten(tau_r)\n",
    "    \n",
    "    lambda_ = np.array([1.5]*rank*d).reshape((rank, d))\n",
    "    omega = [None]*d\n",
    "    for x in range(d):\n",
    "        omega[x] = np.random.exponential(scale=.5*(a_lam[1]/b_lam[1]), size=(rank,p[x]))\n",
    "\n",
    "    beta = [None]*d\n",
    "    for x in range(d):\n",
    "        beta[x] = np.random.normal(size = (rank,p[x]))\n",
    "\n",
    "    ##initialize tensor margins\n",
    "    alpha_store = [None]*nsweep\n",
    "    c0_store = [None]*nsweep\n",
    "    gam_store = np.array([None]*nsweep*pgamma).reshape(nsweep,pgamma)\n",
    "    tau2_store = [None]*nsweep\n",
    "    phi_store = np.array([None]*nsweep*rank).reshape(nsweep,rank)\n",
    "    phi_store\n",
    "    varphi_store = np.array([None]*nsweep*rank).reshape(-1,1)\n",
    "    varphi_store\n",
    "    beta_store = [[None]*d]*nsweep\n",
    "    for x in range(nsweep):\n",
    "        for y in range(d):\n",
    "            beta_store[x][y] = np.array([None]*rank*p[y]).reshape(rank,p[y])\n",
    "    beta_store\n",
    "    omega_store = [[None]*d]*nsweep\n",
    "    for x in range(nsweep):\n",
    "        for y in range(d):\n",
    "            omega_store[x][y] = np.array([None]*rank*p[y]).reshape(rank,p[y])\n",
    "    lambda_store = np.array([None]*nsweep*rank*d).reshape(nsweep,rank, d)\n",
    "    #hyppar_store = np.array([None]*nsweep*rank*d).reshape(nsweep,rank, 2)\n",
    "    hyppar_store = np.zeros((nsweep, rank, 2))\n",
    "\n",
    "    alam_seq = np.linspace(2.1, d + 1, num=5)\n",
    "    zeta_max = np.ceil(10 * rank**(1 / (2 * d)) / 2) / 10\n",
    "    zeta_seq = np.linspace(0.5, zeta_max, num=5)\n",
    "    param_grid = list(itertools.product(alam_seq, zeta_seq))\n",
    "    par_grid = pd.DataFrame(param_grid, columns=['alam', 'zeta'])\n",
    "    alam_seq = np.linspace(2.1, d + 1, num=5)\n",
    "    zeta_max = np.ceil(10 * rank**(1 / (2 * d)) / 2) / 10\n",
    "    zeta_seq = np.linspace(0.5, zeta_max, num=5)\n",
    "    alam_grid, zeta_grid = np.meshgrid(alam_seq, zeta_seq)\n",
    "    par_grid = pd.DataFrame({\n",
    "        'alam': alam_grid.flatten(),\n",
    "        'zeta': zeta_grid.flatten()\n",
    "    })\n",
    "    par_grid = par_grid.values\n",
    "    alpha_grid = np.linspace(rank**(-d), rank**(-0.1), num=10)\n",
    "    M=20\n",
    "    score_store = np.array([None]*nsweep*len(alpha_grid)).reshape(nsweep,len(alpha_grid))\n",
    "\n",
    "    #### MCMC run ####\n",
    "    start_time = time.time()\n",
    "    for sweep in range(nsweep):\n",
    "        tens_mean = getmean(x_train_nona, beta, rank)\n",
    "        Cjr = np.zeros((d, rank))\n",
    "        for rr in range(rank):\n",
    "            for jj in range(d):\n",
    "                bb = np.sum(np.abs(beta[jj][rr, :]))\n",
    "                Cjr[jj, rr] = bb / np.sqrt(tau_r[rr])\n",
    "                #print(\"Cjr[jj, rr]: \", Cjr[jj, rr])\n",
    "        def mfun(z, rank, p, Cjr):\n",
    "            o = [gammaln(z[0] + p[x]) - gammaln(z[0]) + z[0] * math.log(z[1] * z[0]) - (z[0] + p[x]) * math.log(z[1] * z[0] + Cjr[x][rank]) for x in range(d)]\n",
    "            return sum(o)\n",
    "        \n",
    "        ll = np.zeros((par_grid.shape[0], rank))\n",
    "        for rr in range(rank):\n",
    "            for z in range(par_grid.shape[0]):\n",
    "                result = mfun(par_grid[z], rr, p, Cjr)\n",
    "                ll[z, rr] = result\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        par_wt = np.apply_along_axis(lambda z: np.exp(z - logsum(z)), axis=0, arr=ll)\n",
    "        #par_wt = np.apply_along_axis(lambda z: np.exp(z - np.log(np.sum(z))), axis=0, arr=ll)\n",
    "        par_wt = np.nan_to_num(par_wt, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        for i in range(par_wt.shape[1]):\n",
    "            par_wt[:,i] = par_wt[:,i]/np.sum(par_wt[:,i])\n",
    "        par_wt = np.nan_to_num(par_wt, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        # Convert the cleaned NumPy array back to a list\n",
    "        #cleaned_list = cleaned_array.tolist()\n",
    "        #print(\"par_wt:\", sum(par_wt)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        indices = np.arange(par_grid.shape[0])\n",
    "        ixx = np.zeros(par_wt.shape[1], dtype=int)\n",
    "        for i in range(par_wt.shape[1]):\n",
    "            ixx[i] = np.random.choice(indices, size=1, p=par_wt[:, i])[0]\n",
    "        \n",
    "        for rr in range(rank):\n",
    "            a_lam[rr] = par_grid[ixx[rr], 0]\n",
    "            b_lam[rr] = par_grid[ixx[rr], 1] * a_lam[rr]\n",
    "        np.set_printoptions(precision=10, suppress=False)\n",
    "\n",
    "        ##update gamma\n",
    "        diag_pgamma = np.diag(np.ones(pgamma))\n",
    "        cho_factor_matrix = cho_factor(diag_pgamma + ZZ / tau2)\n",
    "        Sig_g = cho_solve(cho_factor_matrix, np.eye(pgamma))\n",
    "        mu_g = np.dot(Sig_g, np.dot(Zt.T, (obs - c0 - tens_mean)) / tau2)\n",
    "        rnorm_pgamma = np.random.normal(size=pgamma)\n",
    "        gam = mu_g + np.dot(np.linalg.cholesky(Sig_g), rnorm_pgamma)\n",
    "\n",
    "        ## update alpha (intercept)\n",
    "        pred_mean = np.dot(Zt, gam)\n",
    "        mu_c0 = np.mean(obs - pred_mean - tens_mean)\n",
    "        c0 = np.random.normal(loc=mu_c0, scale=np.sqrt(tau2 / n))\n",
    "        \n",
    "        ## update tau2\n",
    "        a_tau = a_t + n / 2\n",
    "        b_tau = b_t + 0.5 * np.sum((obs - c0 - pred_mean - tens_mean)**2)\n",
    "        tau2 = 1 / stats.gamma.rvs(a=a_tau, scale=1/b_tau)\n",
    "\n",
    "        ## update (alpha, phi, varphi)\n",
    "        def draw_phi_tau(alpha_grid):\n",
    "            length = len(alpha_grid)\n",
    "\n",
    "            # Precompute Cr matrix\n",
    "            Cr = np.array([\n",
    "                [\n",
    "                    np.dot(beta[jj][rr, :], np.dot(np.diag(1 / omega[jj][rr, :]), beta[jj][rr, :]))\n",
    "                    for rr in range(rank)\n",
    "                ]\n",
    "                for jj in range(d)\n",
    "            ])\n",
    "\n",
    "            def score_fn(phi_alpha, phi_s, varphi_s, Cstat):\n",
    "                def ldirdens(v, a):\n",
    "                    c1 = gammaln(np.sum(a))\n",
    "                    c2 = np.sum(gammaln(a))\n",
    "                    return (c1 - c2) + np.sum((a - 1) * np.log(np.maximum(v, 1e-10)))  \n",
    "\n",
    "                ldir = np.apply_along_axis(ldirdens, 1, phi_s, a=phi_alpha)\n",
    "\n",
    "                lvarphi = stats.gamma.logpdf(varphi_s, a=np.sum(phi_alpha), scale=1/b_vphi)\n",
    "                \n",
    "                dnorm_log = -np.sum(Cstat, axis=1) / (2 * np.maximum(varphi_s, 1e-10)) \n",
    "                dnorm_log -= (np.sum(p) / 2) * np.array([np.sum(np.log(np.maximum(varphi_s[ii] * phi_s[ii, :], 1e-10))) for ii in range(len(varphi_s))])  # Avoid log(0)\n",
    "                \n",
    "                return dnorm_log + ldir + lvarphi\n",
    "\n",
    "            if length > 1:\n",
    "                phi = np.zeros((M * length, rank))\n",
    "                varphi = np.zeros((M * length, 1))\n",
    "                Cstat = np.zeros((M * length, rank))\n",
    "                \n",
    "                for jj in range(length):\n",
    "                    m_phialpha = np.full(rank, alpha_grid[jj])\n",
    "                    m_phia0 = np.sum(m_phialpha)\n",
    "                    m_avphi = m_phia0\n",
    "\n",
    "                    # Draw phi\n",
    "                    Cr1 = np.sum(Cr, axis=0)\n",
    "                    phi_a = np.array([geninvgauss.rvs(m_phialpha[rr] - np.sum(p)/2, Cr1[rr], scale=2 * b_vphi, size=M) for rr in range(rank)]).T\n",
    "                    phi_a = np.apply_along_axis(lambda z: z / np.sum(z), 1, phi_a)\n",
    "\n",
    "                    # Draw varphi\n",
    "                    Cr2 = np.apply_along_axis(lambda z: Cr1 / np.maximum(z, 1e-10), 1, phi_a)  # Avoid division by zero\n",
    "                    varphi_a = np.array([geninvgauss.rvs(m_avphi - rank * np.sum(p)/2, 2 * b_vphi, scale=np.sum(z)) for z in Cr2]).flatten()\n",
    "\n",
    "                    phi[jj * M:(jj + 1) * M, :] = phi_a\n",
    "                    varphi[jj * M:(jj + 1) * M, 0] = varphi_a\n",
    "                    Cstat[jj * M:(jj + 1) * M, :] = Cr2\n",
    "\n",
    "                scores = [score_fn(np.full(rank, z), phi, varphi, Cstat) for z in alpha_grid]\n",
    "                scores = np.array(scores)\n",
    "                lmax = np.max(scores)\n",
    "                normalized_scores = np.array([np.mean(np.exp(score - lmax)) for score in scores])\n",
    "                normalized_scores /= np.sum(normalized_scores)  # Ensure scores sum to 1\n",
    "            else:\n",
    "                m_phialpha = np.full(rank, alpha_grid[0])\n",
    "                m_phia0 = np.sum(m_phialpha)\n",
    "                m_avphi = m_phia0\n",
    "\n",
    "                Cr1 = np.sum(Cr, axis=0)\n",
    "\n",
    "                # Draw phi\n",
    "                phi = np.array([geninvgauss.rvs(m_phialpha[rr] - np.sum(p) / 2, 2 * b_vphi, scale=Cr1[rr], size=1) for rr in range(rank)]).flatten()\n",
    "                phi = phi / np.sum(phi)\n",
    "\n",
    "                # Draw varphi\n",
    "                Cr2 = Cr1 / np.maximum(phi, 1e-10)  # Avoid division by zero\n",
    "                varphi = geninvgauss.rvs(m_avphi - rank * np.sum(p) / 2, 2 * b_vphi, scale=np.sum(Cr2), size=1)\n",
    "\n",
    "                scores = score_fn(m_phialpha, np.array([phi]), np.array([varphi]), np.array([Cr2]))\n",
    "                scores = np.array([scores])\n",
    "                lmax = np.max(scores)\n",
    "                normalized_scores = np.array([np.mean(np.exp(scores - lmax))])\n",
    "                normalized_scores /= np.sum(normalized_scores)  # Ensure scores sum to 1\n",
    "\n",
    "            return {'phi': phi, 'varphi': varphi, 'scores': normalized_scores}\n",
    "        ## sample astar\n",
    "        o = draw_phi_tau(alpha_grid)\n",
    "        scores = o['scores']\n",
    "        normalized_scores = scores / np.sum(scores)\n",
    "        astar = np.random.choice(alpha_grid, size=1, p=normalized_scores)\n",
    "        score_store[sweep, :] = normalized_scores\n",
    "\n",
    "        # Sample (phi, varphi) based on astar\n",
    "        o = draw_phi_tau(astar)\n",
    "        phi = o['phi']\n",
    "        varphi = o['varphi']\n",
    "\n",
    "        # Calculate tau.r\n",
    "        tau_r = varphi * phi\n",
    "        #print(\"tau_r: \", tau_r)\n",
    "        # Define phi.alpha, phi.a0, and a.vphi\n",
    "        phi_alpha = np.full(rank, astar)\n",
    "        phi_a0 = np.sum(phi_alpha)\n",
    "        a_vphi = phi_a0\n",
    "\n",
    "        ## update rank specific params\n",
    "        lambda_ = np.zeros((rank, len(beta)))\n",
    "        for r in range(rank):\n",
    "            for j in range(d):\n",
    "                tens_mu_r = getmean(x_train_nona, beta, rank, [r])\n",
    "                    \n",
    "                betj = getouter_list([beta_elem[r, :] for k, beta_elem in enumerate(beta) if k != j])\n",
    "                    \n",
    "                H = np.full((n, p[j]), np.nan)\n",
    "                for i in range(n):\n",
    "                    if d == 2:\n",
    "                        if j == 0:\n",
    "                            H[i, :] = [np.sum(x_train_nona[i, k, :] * betj) for k in range(p[j])]\n",
    "                        elif j == 1:\n",
    "                                H[i, :] = [np.sum(x_train_nona[i, :, k] * betj) for k in range(p[j])]\n",
    "                    elif d == 3:\n",
    "                        if j == 0:\n",
    "                            H[i, :] = [np.sum(x_train_nona[i, k, :, :] * betj) for k in range(p[j])]\n",
    "                        elif j == 1:\n",
    "                            H[i, :] = [np.sum(x_train_nona[i, :, k, :] * betj) for k in range(p[j])]\n",
    "                        elif j == 2:\n",
    "                            H[i, :] = [np.sum(x_train_nona[i, :, :, k] * betj) for k in range(p[j])]\n",
    "                #print(\"H: \", H)\n",
    "                HH = np.dot(H.T, H)\n",
    "                #print(\"HH: \", HH)\n",
    "                diag_elements = 1 / omega[j][r, :] / tau_r[r]\n",
    "                diag_matrix = np.diag(diag_elements)\n",
    "                #print(\"HH / tau2 + diag_matrix: \", HH / tau2 + diag_matrix)\n",
    "                chol_matrix = cholesky(HH / tau2 + diag_matrix)\n",
    "                K = inv(chol_matrix.T @ chol_matrix)\n",
    "                #K = inv(chol_matrix)\n",
    "                #print(\"K:\", K)\n",
    "                \n",
    "                ##update betas\n",
    "                mm = obs - c0 - pred_mean - tens_mu_r\n",
    "                bet_mu_jr = K @ ((H.T/tau2)@ mm)\n",
    "                chol_K = cholesky(K, lower=True)\n",
    "                beta[j][r, :] = bet_mu_jr + chol_K @ np.random.randn(p[j])\n",
    "\n",
    "                ## update lambda.jr\n",
    "                shape = a_lam[r] + p[j]\n",
    "                rate = b_lam[r] + np.sum(np.abs(beta[j][r, :])) / np.sqrt(tau_r[r]) \n",
    "                lambda_[r, j] = np.random.gamma(shape, 1.0 / rate)\n",
    "                ## update omega.jr\n",
    "                omega[j][r, :] = [geninvgauss.rvs(0.5, beta[j][r, kk]**2 / tau_r[r], scale=lambda_[r, j]**2) for kk in range(p[j])]\n",
    "        \n",
    "        ## store params\n",
    "        tau2_store[sweep] = tau2\n",
    "        c0_store[sweep] = c0\n",
    "        if z_train is not None:\n",
    "            gam_store[sweep, :] = gam\n",
    "        else:\n",
    "            gam_store[sweep] = gam\n",
    "        alpha_store[sweep] = astar\n",
    "        phi_store[sweep, :] = phi\n",
    "        varphi_store[sweep, :] = varphi\n",
    "        beta_store[sweep] = beta\n",
    "        omega_store[sweep] = omega\n",
    "        lambda_store[sweep, :, :] = lambda_\n",
    "        for rr in range(rank):\n",
    "            hyppar_store[sweep, rr, :] = [a_lam[rr], b_lam[rr]]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        #if sweep % 5 == 0:\n",
    "            #print(f\"{sweep}, tau2: {tau2 * sy**2:.3f}, (alpha, a.lam, b.lam): {astar:.3f}, {a_lam[r]:.3f}, {b_lam[r]:.3f}\")\n",
    "    \n",
    "    # Example time-consuming operation\n",
    "    time.sleep(0.01)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = abs(end_time - start_time)\n",
    "    print('Time out:', elapsed_time)\n",
    "\n",
    "    out = {\n",
    "    \"nsweep\": nsweep,\n",
    "    \"rank\": rank,\n",
    "    \"p\": p,\n",
    "    \"d\": d,\n",
    "    \"par_grid\": par_grid,\n",
    "    \"alpha_grid\": alpha_grid,\n",
    "    \"my\": my,\n",
    "    \"sy\": sy,\n",
    "    \"mz\": mz,\n",
    "    \"sz\": sz,\n",
    "    \"mx\": mx,\n",
    "    \"sx\": sx,\n",
    "    \"Zt\": Zt,\n",
    "    \"Xt\": Xt,\n",
    "    \"obs\": obs,\n",
    "    \"a_t\": a_t,\n",
    "    \"b_t\": b_t,\n",
    "    \"tau2_store\": tau2_store,\n",
    "    \"c0_store\": c0_store,\n",
    "    \"gam_store\": gam_store,\n",
    "    \"alpha_store\": alpha_store,\n",
    "    \"beta_store\": beta_store,\n",
    "    \"phi_store\": phi_store,\n",
    "    \"varphi_store\": varphi_store,\n",
    "    \"omega_store\": omega_store,\n",
    "    \"lambda_store\": lambda_store,\n",
    "    \"hyppar_store\": hyppar_store,\n",
    "    \"score_store\": score_store,\n",
    "    \"time\": elapsed_time\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_1 = (X_train[:, 32, 19, 34] <= 3.8721486171364994) & (X_train[:, 28, 20, 18] <= 2.165013522178203)\n",
    "group_1_y = y_train[indices_1]\n",
    "\n",
    "# Leaf Node 2\n",
    "indices_2 = (X_train[:, 32, 19, 34] <= 3.8721486171364994) & (X_train[:, 28, 20, 18] > 2.165013522178203)\n",
    "group_2_y = y_train[indices_2]\n",
    "\n",
    "# Leaf Node 3\n",
    "indices_3 = (X_train[:, 32, 19, 34] > 3.8721486171364994) & (X_train[:, 32, 26, 37] <= 4.602050602265279)\n",
    "group_3_y = y_train[indices_3]\n",
    "\n",
    "# Leaf Node 4\n",
    "indices_4 = (X_train[:, 32, 19, 34] > 3.8721486171364994) & (X_train[:, 32, 26, 37] > 4.602050602265279)\n",
    "group_4_y = y_train[indices_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.zeros((len(indices_1), 1))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 48, 48, 48)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[indices_1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time out: 123.75880599021912\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros((93, 1))\n",
    "from skimage.measure import block_reduce\n",
    "X_coarsen_shape = (1,4,4,4)\n",
    "X_coarsen_func = np.mean\n",
    "X_train_c = block_reduce(X_train[indices_1],block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "#X_test_c = block_reduce(X_test,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_train_c = X_train_c + np.random.randn(*X_train_c.shape) * 1e-3\n",
    "nsweep = 1000\n",
    "rank = 6\n",
    "burn = 0.3\n",
    "nskip = 1\n",
    "nsamp = int(np.floor((1 - burn) * nsweep / nskip))\n",
    "ss = np.ceil(np.linspace(burn, 1, nsamp) * nsweep).astype(int) - 1  # adjust for 0-based indexing\n",
    "out = tensor_reg(z_train=z.reshape(len(z),1), x_train = X_train_c, y_train = group_1_y, nsweep = nsweep, rank = rank, burn = burn, nskip = nskip, scale=True, a_lam= None, b_lam=None, phi_alpha=None, plot=True)\n",
    "\n",
    "# Compute Beta_mcmc\n",
    "Beta_mcmc = getBeta_mcmc(out['beta_store'])\n",
    "# Compute Beta_est\n",
    "p = [out[\"beta_store\"][0][x].shape[1] for x in range(len(out[\"beta_store\"][0]))]\n",
    "\n",
    "Beta_est = (out['sy'] / out['sx']) * np.mean(Beta_mcmc[ss, :], axis=0).reshape(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.161333927049805\n"
     ]
    }
   ],
   "source": [
    "err = 0\n",
    "for i in range(X_train_c.shape[0]):\n",
    "    err += (np.tensordot(X_train_c[i], Beta_est, axes=((0, 1, 2), (0, 1, 2)))-y_train[i])**2\n",
    "mse = err/X_train_c.shape[0]\n",
    "rmse = mse/np.var(y_train)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time out: 142.89861702919006\n",
      "5.6446546921430265\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros((129, 1))\n",
    "from skimage.measure import block_reduce\n",
    "X_coarsen_shape = (1,4,4,4)\n",
    "X_coarsen_func = np.mean\n",
    "X_train_c = block_reduce(X_train[indices_2],block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "#X_test_c = block_reduce(X_test,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_train_c = X_train_c + np.random.randn(*X_train_c.shape) * 1e-4\n",
    "nsweep = 1000\n",
    "rank = 6\n",
    "burn = 0.3\n",
    "nskip = 1\n",
    "nsamp = int(np.floor((1 - burn) * nsweep / nskip))\n",
    "ss = np.ceil(np.linspace(burn, 1, nsamp) * nsweep).astype(int) - 1  # adjust for 0-based indexing\n",
    "out = tensor_reg(z_train=z.reshape(len(z),1), x_train = X_train_c, y_train = group_2_y, nsweep = nsweep, rank = rank, burn = burn, nskip = nskip, scale=True, a_lam= None, b_lam=None, phi_alpha=None, plot=True)\n",
    "\n",
    "# Compute Beta_mcmc\n",
    "Beta_mcmc = getBeta_mcmc(out['beta_store'])\n",
    "# Compute Beta_est\n",
    "p = [out[\"beta_store\"][0][x].shape[1] for x in range(len(out[\"beta_store\"][0]))]\n",
    "\n",
    "Beta_est = (out['sy'] / out['sx']) * np.mean(Beta_mcmc[ss, :], axis=0).reshape(p)\n",
    "err = 0\n",
    "for i in range(X_train_c.shape[0]):\n",
    "    err += (np.tensordot(X_train_c[i], Beta_est, axes=((0, 1, 2), (0, 1, 2)))-y_train[i])**2\n",
    "mse = err/X_train_c.shape[0]\n",
    "rmse = mse/np.var(y_train)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time out: 137.30868315696716\n",
      "12.835545523109538\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros((118, 1))\n",
    "from skimage.measure import block_reduce\n",
    "X_coarsen_shape = (1,4,4,4)\n",
    "X_coarsen_func = np.mean\n",
    "X_train_c = block_reduce(X_train[indices_3],block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "#X_test_c = block_reduce(X_test,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_train_c = X_train_c + np.random.randn(*X_train_c.shape) * 1e-4\n",
    "nsweep = 1000\n",
    "rank = 6\n",
    "burn = 0.3\n",
    "nskip = 1\n",
    "nsamp = int(np.floor((1 - burn) * nsweep / nskip))\n",
    "ss = np.ceil(np.linspace(burn, 1, nsamp) * nsweep).astype(int) - 1  # adjust for 0-based indexing\n",
    "out = tensor_reg(z_train=z.reshape(len(z),1), x_train = X_train_c, y_train = group_3_y, nsweep = nsweep, rank = rank, burn = burn, nskip = nskip, scale=True, a_lam= None, b_lam=None, phi_alpha=None, plot=True)\n",
    "\n",
    "# Compute Beta_mcmc\n",
    "Beta_mcmc = getBeta_mcmc(out['beta_store'])\n",
    "# Compute Beta_est\n",
    "p = [out[\"beta_store\"][0][x].shape[1] for x in range(len(out[\"beta_store\"][0]))]\n",
    "\n",
    "Beta_est = (out['sy'] / out['sx']) * np.mean(Beta_mcmc[ss, :], axis=0).reshape(p)\n",
    "err = 0\n",
    "for i in range(X_train_c.shape[0]):\n",
    "    err += (np.tensordot(X_train_c[i], Beta_est, axes=((0, 1, 2), (0, 1, 2)))-y_train[i])**2\n",
    "mse = err/X_train_c.shape[0]\n",
    "rmse = mse/np.var(y_train)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time out: 196.3312587738037\n",
      "5.10881059714307\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros((231, 1))\n",
    "from skimage.measure import block_reduce\n",
    "X_coarsen_shape = (1,4,4,4)\n",
    "X_coarsen_func = np.mean\n",
    "X_train_c = block_reduce(X_train[indices_4],block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "#X_test_c = block_reduce(X_test,block_size=X_coarsen_shape, func=X_coarsen_func)\n",
    "X_train_c = X_train_c + np.random.randn(*X_train_c.shape) * 1e-4\n",
    "nsweep = 1000\n",
    "rank = 6\n",
    "burn = 0.3\n",
    "nskip = 1\n",
    "nsamp = int(np.floor((1 - burn) * nsweep / nskip))\n",
    "ss = np.ceil(np.linspace(burn, 1, nsamp) * nsweep).astype(int) - 1  # adjust for 0-based indexing\n",
    "out = tensor_reg(z_train=z.reshape(len(z),1), x_train = X_train_c, y_train = group_4_y, nsweep = nsweep, rank = rank, burn = burn, nskip = nskip, scale=True, a_lam= None, b_lam=None, phi_alpha=None, plot=True)\n",
    "\n",
    "# Compute Beta_mcmc\n",
    "Beta_mcmc = getBeta_mcmc(out['beta_store'])\n",
    "# Compute Beta_est\n",
    "p = [out[\"beta_store\"][0][x].shape[1] for x in range(len(out[\"beta_store\"][0]))]\n",
    "\n",
    "Beta_est = (out['sy'] / out['sx']) * np.mean(Beta_mcmc[ss, :], axis=0).reshape(p)\n",
    "err = 0\n",
    "for i in range(X_train_c.shape[0]):\n",
    "    err += (np.tensordot(X_train_c[i], Beta_est, axes=((0, 1, 2), (0, 1, 2)))-y_train[i])**2\n",
    "mse = err/X_train_c.shape[0]\n",
    "rmse = mse/np.var(y_train)\n",
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
